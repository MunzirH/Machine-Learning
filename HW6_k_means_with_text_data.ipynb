{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiWfDa1yo2go"
   },
   "source": [
    "# Homework 6 - Implementing k-means with Text Data\n",
    "\n",
    "### Coding Portion on EdStem and Concept on Gradescope\n",
    "\n",
    "In this assignment you will implement the k-means algorithm in the specific setting of clustering text documents, but the algorithm is general to any setting. When properly executed, clustering uncovers valuable insights from a set of unlabeled documents. The assignment uses the `numpy` library for manipulating the data arrays. See [this tutorial](https://numpy.org/doc/stable/user/quickstart.html) for more information on numpy.\n",
    "\n",
    "In this assignment, you will practice:\n",
    "\n",
    "* Cluster Wikipedia documents using k-means\n",
    "* Explore the role of random initialization on the quality of the clustering\n",
    "* Explore how results differ after changing the number of clusters\n",
    "* Evaluate clustering, both quantitatively and qualitatively\n",
    "\n",
    "Fill in the cells provided marked `TODO` with code to answer the questions. **Unless otherwise noted, every answer you submit should have code that clearly shows the answer in the output.** Answers submitted that do not have associated code that shows the answer may not be accepted for credit. \n",
    "\n",
    "**Make sure to restart the kernel and run all cells** (especially before turning it in) to make sure your code runs correctly. Answer the questions on Gradescope and make sure to download this file once you've finished the assignment and upload it to Canvas as well.\n",
    "\n",
    "> Copyright ¬©2021 Emily Fox and Hunter Schafer.  All rights reserved.  Permission is hereby granted to students registered for University of Washington CSE/STAT 416 for use solely during Autumn Quarter 2021 for purposes of the course.  No other use, copying, distribution, or modification is permitted without prior written consent. Copyrights for third-party components of this work must be honored.  Instructors interested in reusing these course materials should contact the author.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ceTONP5so2gq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfLHXS7Mo2gr"
   },
   "source": [
    "# Load data, Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "setANGGZo2gs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Mauno_J%C3%A4rvel...</td>\n",
       "      <td>Mauno J%C3%A4rvel%C3%A4</td>\n",
       "      <td>mauno jrvel born 25 november 1949 in kaustinen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/David_W._Jourdan&gt;</td>\n",
       "      <td>David W. Jourdan</td>\n",
       "      <td>david walter jourdan born december 5 1954 is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Patrick_Roach&gt;</td>\n",
       "      <td>Patrick Roach</td>\n",
       "      <td>patrick roach born march 4 1969 is a canadian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Louis_Sauer&gt;</td>\n",
       "      <td>Louis Sauer</td>\n",
       "      <td>louis lou sauer aka louis edward sauer born 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Marty_Keough&gt;</td>\n",
       "      <td>Marty Keough</td>\n",
       "      <td>richard martin keough born april 14 1934 in oa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URI                     name  \\\n",
       "0  <http://dbpedia.org/resource/Mauno_J%C3%A4rvel...  Mauno J%C3%A4rvel%C3%A4   \n",
       "1     <http://dbpedia.org/resource/David_W._Jourdan>         David W. Jourdan   \n",
       "2        <http://dbpedia.org/resource/Patrick_Roach>            Patrick Roach   \n",
       "3          <http://dbpedia.org/resource/Louis_Sauer>              Louis Sauer   \n",
       "4         <http://dbpedia.org/resource/Marty_Keough>             Marty Keough   \n",
       "\n",
       "                                                text  \n",
       "0  mauno jrvel born 25 november 1949 in kaustinen...  \n",
       "1  david walter jourdan born december 5 1954 is a...  \n",
       "2  patrick roach born march 4 1969 is a canadian ...  \n",
       "3  louis lou sauer aka louis edward sauer born 19...  \n",
       "4  richard martin keough born april 14 1934 in oa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = pd.read_csv('people_wiki.csv')\n",
    "wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp6rerafo2gs"
   },
   "source": [
    "To work with text data, we must first convert the documents into numerical features. Like Assignment 3, let's extract TF-IDF features for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "tjhkztcpo2gs"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.95)  # ignore words with very high doc frequency\n",
    "tf_idf = vectorizer.fit_transform(wiki['text'])\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWme47Spo2gt"
   },
   "source": [
    "Since most documents don't contain every word, many of the TF-IDF entries will be 0. Representing the TF-IDF matrix as a `numpy` matrix will require a lot of unnecessary storage to keep track of all those 0. SciPy provides the idea of a \"sparse matrix\" that only represents the non-zero entries of a matrix to save space. Externally, you treat it just like a numpy `matrix` but it takes up less storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "ZItU_xhko2gu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5907, 112801)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = csr_matrix(tf_idf)\n",
    "\n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t516ujM_o2gv"
   },
   "source": [
    "The above matrix contains a TF-IDF score for each of the 5907 pages in the data set and each of the 112801 unique words. You can treat it like any matrix of data but internally it is space-efficient since it knows not to store the zero word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMif9Q0mo2gv"
   },
   "source": [
    "# Normalize all vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_ESjxfSo2gw"
   },
   "source": [
    "As discussed in the previous assignment, Euclidean distance can be a poor metric of similarity between documents, as it unfairly penalizes long articles. For a reasonable assessment of similarity, we should disregard the length information and use length-agnostic metrics, such as cosine distance.\n",
    "\n",
    "The k-means algorithm does not directly work with cosine distance, so we take an alternative route to remove length information: we normalize all vectors to be unit length. It turns out that Euclidean distance closely mimics cosine distance when all vectors are unit length. In particular, the squared Euclidean distance between any two vectors of length one is directly proportional to their cosine distance.\n",
    "\n",
    "---\n",
    "\n",
    "### Optional: Justification\n",
    "This section has some optional background material as to why normalizing makes sense here. You can skip down to the next line break if you don't want to read this.\n",
    "\n",
    "We can prove this as follows. Let $\\mathbf{x}$ and $\\mathbf{y}$ be normalized vectors, i.e. unit vectors, so that $\\|\\mathbf{x}\\|=\\|\\mathbf{y}\\|=1$. Write the squared Euclidean distance as the dot product of $(\\mathbf{x} - \\mathbf{y})$ to itself:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\|\\mathbf{x} - \\mathbf{y}\\|_2^2 &= (\\mathbf{x} - \\mathbf{y})^T(\\mathbf{x} - \\mathbf{y}) & \\text{(def of L2 norm)}\\\\\n",
    "                              &= (\\mathbf{x}^T \\mathbf{x}) - 2(\\mathbf{x}^T \\mathbf{y}) + (\\mathbf{y}^T \\mathbf{y}) & \\text{(FOIL expression)}\\\\\n",
    "                              &= \\|\\mathbf{x}\\|_2^2 - 2(\\mathbf{x}^T \\mathbf{y}) + \\|\\mathbf{y}\\|_2^2 & \\text{(def of L2 norm)}\\\\\n",
    "                              &= 2 - 2(\\mathbf{x}^T \\mathbf{y}) & \\text{($\\mathbf{x}$ and $\\mathbf{y}$ are length 1)}\\\\\n",
    "                              &= 2(1 - (\\mathbf{x}^T \\mathbf{y}))\\\\\n",
    "                              &= 2\\left(1 - \\frac{\\mathbf{x}^T \\mathbf{y}}{\\|\\mathbf{x}\\|_2\\|\\mathbf{y}\\|_2}\\right) & \\text{(Dividing by 1 doesn't change value)}\\\\\n",
    "                              &= 2 \\cdot cosine\\_distance(\\mathbf{x}, \\mathbf{y})\n",
    "\\end{align*}$$\n",
    "\n",
    "This tells us that two **unit vectors** that are close in Euclidean distance are also close in cosine distance. Thus, the k-means algorithm (which naturally uses Euclidean distances) on normalized vectors will produce the same results as clustering using cosine distance as a distance metric.\n",
    "\n",
    "*End optional section*.\n",
    "\n",
    "---\n",
    "We import the [`normalize()` function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html) from scikit-learn to normalize all vectors to unit length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "VzNdGbGdo2gw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5907x112801 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 993501 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "tf_idf = normalize(tf_idf)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n64QJfEXo2gy"
   },
   "source": [
    "# Implement k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5c57x6Zo2gz"
   },
   "source": [
    "The bulk of this assignment will be implementing k-means. We will tackle it in parts to make it manageable.\n",
    "\n",
    "First, we choose an initial set of centroids. A common practice is to choose randomly from the data points.\n",
    "\n",
    "**Note:** We specify a seed here, so that everyone gets the same answer. In practice, we highly recommend to use different seeds every time (for instance, by using the current timestamp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "Glm_VuNCo2gz"
   },
   "outputs": [],
   "source": [
    "def get_initial_centroids(data, k, seed=None):\n",
    "    \"\"\"\n",
    "    Randomly choose k data points as initial centroids\n",
    "    \"\"\"\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    n = data.shape[0] # number of data points\n",
    "        \n",
    "    # Pick K indices from range [0, n).\n",
    "    rand_indices = np.random.randint(0, n, k)\n",
    "    \n",
    "    # Keep centroids as dense format, as many entries will be nonzero due to averaging.\n",
    "    # As long as at least one document in a cluster contains a word,\n",
    "    # it will carry a nonzero weight in the TF-IDF vector of the centroid.\n",
    "    centroids = data[rand_indices,:].toarray()\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEeFd0PBo2g0"
   },
   "source": [
    "### k-means Algorithm\n",
    "After initialization, the k-means algorithm iterates between the following two steps:\n",
    "1. Assign each data point to the closest centroid. $$z_i \\gets \\mathrm{argmin}_j \\|\\mathbf{\\mu}_j - \\mathbf{x}_i\\|^2$$\n",
    "2. Revise centroids as the mean of the assigned data points. $$\\mathbf{\\mu}_j \\gets \\frac{1}{n_j}\\sum_{i:z_i=j} \\mathbf{x}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H92_8B9So2g0"
   },
   "source": [
    "In pseudocode, we iteratively do the following:\n",
    "```python\n",
    "cluster_assignment = assign_clusters(data, centroids)\n",
    "centroids = revise_centroids(data, k, cluster_assignment)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyHkFDy0o2g0"
   },
   "source": [
    "## Assigning clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUgGWFe-o2g0"
   },
   "source": [
    "How do we implement Step 1 of the main k-means loop above? First we import `pairwise_distances` function from scikit-learn, which calculates Euclidean distances between rows of given arrays. See [this documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_distances.html) for more information.\n",
    "\n",
    "For the sake of demonstration, let's look at documents 100 through 102 as query documents and compute the distances between each of these documents and every other document in the corpus. In the k-means algorithm, we will have to compute pairwise distances between the set of centroids and the set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "GWs-Fn0_o2g1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.39996239 1.39958932]\n",
      " [1.40386156 1.39754968]\n",
      " [1.38421176 1.39682604]\n",
      " ...\n",
      " [1.40562888 1.39024794]\n",
      " [1.39673862 1.38306708]\n",
      " [1.40872806 1.40250208]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Get the TF-IDF vectors for documents 100 through 102.\n",
    "queries = tf_idf[100:102,:]\n",
    "\n",
    "# Compute pairwise distances from every data point to each query vector.\n",
    "dist = pairwise_distances(tf_idf, queries, metric='euclidean')\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Iln_9UMo2g1"
   },
   "source": [
    "More formally, `dist[i,j]` is assigned the distance between the `i`th row of `X` (i.e., `X[i,:]`) and the `j`th row of `Y` (i.e., `Y[j,:]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hFrWT1Yo2g1"
   },
   "source": [
    "## üîç **Question 1** Computing Distances\n",
    "\n",
    "To test your understanding of how this code works, in the cell below write practice code that does the following tasks\n",
    "\n",
    "* Initializes 3 centroids that are the first 3 rows of `tf_idf`\n",
    "* Compute the distances between all the points in `tf_idf` and the 3 centroids. The result should be a matrix with shape `(5907, 3)`. Store this in a variable called `distances`.\n",
    "* Use `distances` to find the distance between the row of `tf_idf` with index 430 to the second centroid (index 1). Store this value in a variable called `dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "hNwsXNG9o2g2"
   },
   "outputs": [],
   "source": [
    "### edTest(test_q1_computing_distances) ###\n",
    "\n",
    "# TODO Fill out this cell\n",
    "#Initializing the 3 centroids\n",
    "centroids = tf_idf[:3,:]\n",
    "#Computing the distances\n",
    "distances = pairwise_distances(tf_idf, centroids, metric='euclidean')\n",
    "#print(distances.shape)\n",
    "#Distance between the 430th row and the second centroid\n",
    "dist = distances[430, 1]\n",
    "#print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0UQT5SKo2g2"
   },
   "source": [
    "## üîç **Question 2** Find closest centroid\n",
    "\n",
    "Next, given the pairwise distances, we take the minimum of the distances for each data point. Fittingly, NumPy provides an `argmin` function. See [this documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.argmin.html) for details. After reading the documentation, in the cell below, write code to produce a 1D array whose $i^{th}$ entry indicates the centroid index that is the closest to the $i^{th}$ data point.\n",
    "\n",
    "Use the list of distances from the previous question. Following the theme of this case study, we will judge whether the clustering makes sense in the context of document analysis. Save this array as `closest_cluster`.\n",
    "\n",
    "As a note, it would be very slow to compute if you do not use the `argmin`. If you want your notebook to run in a reasonable amount of time, you will need to use the `argmin` function.\n",
    "\n",
    "*Hint:* the resulting array should be as long as the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "R2-F7gC5o2g2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "### edTest(test_q2_closest_centroid) ###\n",
    "\n",
    "# TODO Fill out this cell\n",
    "closest_cluster=np.argmin(distances, axis=1)\n",
    "print(closest_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c990JKsao2g3"
   },
   "source": [
    "## üîç **Question 3** Assign Clusters\n",
    "\n",
    "Now that we have completed components of the Step 1 code, let's put it together in a single function that takes a dataset and centroids and assigns each row to the closest centroid.Now we are ready to fill in the blanks the function `assign_clusters(data, centroids)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "lm7fcVdCo2g3"
   },
   "outputs": [],
   "source": [
    "### edTest(test_q3_assign_clusters) ###\n",
    "\n",
    "# TODO Complete this function\n",
    "def assign_clusters(data, centroids):\n",
    "    \"\"\"\n",
    "    Parameters:  \n",
    "      - data      - is an np.array of float values of length n.  \n",
    "      - centroids - is an np.array of float values of length k.\n",
    "\n",
    "    Returns  \n",
    "      -  A np.array of length n where the ith index represents which centroid \n",
    "         data[i] was assigned to. The assignments range between the values 0, ..., k-1.\n",
    "    \"\"\"\n",
    "    # TODO Implement this function\n",
    "    return np.argmin(pairwise_distances(data, centroids, metric='euclidean'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWkIrMQvo2g3"
   },
   "source": [
    "# Revising clusters\n",
    "\n",
    "## Numpy Tutorial\n",
    "Let's turn to Step 2 of the k-means algorithm, where we compute the new centroids given the current cluster assignments. \n",
    "\n",
    "SciPy and NumPy arrays allow for filtering via Boolean masks. For instance, we filter all data points that are assigned to cluster 0 by writing\n",
    "\n",
    "```python\n",
    "data[cluster_assignment == 0, :]\n",
    "```\n",
    "\n",
    "To develop intuition about filtering, let's look at a small example consisting of 3 data points and 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "ip8G0lcso2g3"
   },
   "outputs": [],
   "source": [
    "data = np.array([[1., 2., 0.],\n",
    "                 [0., 0., 0.],\n",
    "                 [2., 2., 0.]])\n",
    "centroids = np.array([[0.5, 0.5, 0.],\n",
    "                      [0., -0.5, 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFm2E7OKo2g4"
   },
   "source": [
    "Let's assign these data points to the closest centroid using the function you wrote before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "YiSiyNhNo2g4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment = assign_clusters(data, centroids)\n",
    "cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4B2rRQfo2g4"
   },
   "source": [
    "The expression `cluster_assignment == 1` gives a list of Booleans that says whether each data point is assigned to cluster 1 or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "yakykT0co2g4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIxAztyho2g4"
   },
   "source": [
    "Likewise for cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "v5AWTe8Yo2g4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeCc0EaXo2g5"
   },
   "source": [
    "Instead of indices, we can also put in the list of Booleans to pick and choose rows. Only the rows that correspond to a `True` entry will be retained.\n",
    "\n",
    "First, let's look at the data points (i.e., their values) assigned to cluster 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "mTwpHapRo2g5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuuberARo2g5"
   },
   "source": [
    "This makes sense since the vector `[0 0 0]` is closer to the centroid `[0 -0.5 0]` than to the centroid `[0.5 0.5 0]`.\n",
    "\n",
    "Now let's look at the data points assigned to cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "Czh-v5Bqo2g5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 0.],\n",
       "       [2., 2., 0.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NsRimvEo2g5"
   },
   "source": [
    "Again, this makes sense since these values are each closer to the centroid `[0.5 0.5 0]` than to `[0 -0.5 0]`.\n",
    "\n",
    "Given all the data points in a cluster, it only remains to compute the mean. Use [np.mean()](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.mean.html). By default, the function averages all elements in a 2D array. To compute row-wise or column-wise means, add the `axis` argument. See the linked documentation for details. \n",
    "\n",
    "In the cell below, we first find all the rows that were assigned cluster 0 and then take the average of those vectors to find the new cluster 0 centroid. Notice that the result will be an np.array with 3 elements because that's the dimensionality of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "oWUrI8H7o2g5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 2. , 0. ])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTD6v4Sao2g6"
   },
   "source": [
    "## üîç **Question 4** Revise Centroids\n",
    "\n",
    "\n",
    "Now we are ready to fill in the blanks the function `revise_centroids(data, k, cluster_assignment)`. In the cell below, complete the `...` sections to compute the new centroids given the current cluster assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Q-HN9vXno2g6"
   },
   "outputs": [],
   "source": [
    "### edTest(test_q4_revise_centroids) ###\n",
    "\n",
    "# TODO fill in this function\n",
    "def revise_centroids(data, k, cluster_assignment):\n",
    "    \"\"\"\n",
    "    Parameters:  \n",
    "      - data               - is an np.array of float values of length n.\n",
    "      - k                  - number of centroids\n",
    "      - cluster_assignment - np.array of length n where the ith index represents which \n",
    "                             centroid data[i] was assigned to. The assignments range between the values 0, ..., k-1.\n",
    "\n",
    "    Returns  \n",
    "      -  A np.array of length k for the new centroids.\n",
    "    \"\"\"\n",
    "    new_centroids = []\n",
    "    for i in range(k):\n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment == i]\n",
    "        # Compute the mean of the data points. Fill in the blank (RHS only)\n",
    "        centroid = np.mean(member_data_points, axis = 0)\n",
    "        \n",
    "        # Convert numpy.matrix type to numpy.ndarray type\n",
    "        centroid = centroid.A1\n",
    "        new_centroids.append(centroid)\n",
    "        \n",
    "    new_centroids = np.array(new_centroids)\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtHVvmZ0o2g7"
   },
   "source": [
    "# Assessing convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-bICx7Ko2g7"
   },
   "source": [
    "How can we tell if the k-means algorithm is converging? We can look at the cluster assignments and see if they stabilize over time. In fact, we'll be running the algorithm until the cluster assignments stop changing at all. To be extra safe, and to assess the clustering performance, we'll be looking at an additional criteria: the sum of all squared distances between data points and centroids. This is defined as\n",
    "$$\n",
    "J(\\mathcal{Z},\\mu) = \\sum_{j=0}^{k-1} \\sum_{i=1:z_i = j}^n \\|\\mathbf{x}_i - \\mu_j\\|^2.\n",
    "$$\n",
    "The smaller the distances, the more homogeneous the clusters are. In other words, we'd like to have \"tight\" clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "oMXXy-1po2g7"
   },
   "outputs": [],
   "source": [
    "def compute_heterogeneity(data, k, centroids, cluster_assignment):\n",
    "    \"\"\"\n",
    "    Computes the heterogeneity metric of the data using the given centroids and cluster assignments.\n",
    "    \"\"\"\n",
    "    heterogeneity = 0.0\n",
    "    for i in range(k):\n",
    "        \n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment == i, :]\n",
    "        \n",
    "        if member_data_points.shape[0] > 0: # check if i-th cluster is non-empty\n",
    "            # Compute distances from centroid to data point\n",
    "            distances = pairwise_distances(member_data_points, [centroids[i]], metric='euclidean')\n",
    "            squared_distances = distances ** 2\n",
    "            heterogeneity += np.sum(squared_distances)\n",
    "        \n",
    "    return heterogeneity\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJTwGp7No2g7"
   },
   "source": [
    "Let's compute the cluster heterogeneity for the 2-cluster example we've been considering based on our current cluster assignments and centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "hwM166nAo2g7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(compute_heterogeneity(data, 2, centroids, cluster_assignment))\n",
    "cluster_assignment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEkoWc6po2g8"
   },
   "source": [
    "# üîç **Question 5** Combining into a single function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nlMU9fxo2g8"
   },
   "source": [
    "Once the two k-means steps have been implemented, as well as our heterogeneity metric we wish to monitor, it is only a matter of putting these functions together to write a k-means algorithm that\n",
    "\n",
    "* Repeatedly performs Steps 1 and 2\n",
    "* Tracks convergence metrics on each iteration\n",
    "* Stops if either no assignment changed or we reach a certain number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3nS9YNeo2g8"
   },
   "source": [
    "Now we are ready to fill in the blanks the function `kmeans(data, k, initial_centroids, maxiter, record_heterogeneity=None, verbose=False)`. In the cell below, complete the `...` sections to meet the specification of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "CuA7bfh8o2g8"
   },
   "outputs": [],
   "source": [
    "### edTest(test_q5_kmeans) ###\n",
    "\n",
    "# TODO Fill in the blanks\n",
    "def kmeans(data, k, initial_centroids, max_iter, record_heterogeneity=None, verbose=False):\n",
    "    \"\"\"\n",
    "    This function runs k-means on given data and initial set of centroids.\n",
    "    \n",
    "    Parameters:  \n",
    "      - data                 - is an np.array of float values of length N.\n",
    "      - k                    - number of centroids\n",
    "      - initial_centroids    - is an np.array of float values of length k.\n",
    "      - max_iter             - maximum number of iterations to run the algorithm\n",
    "      - record_heterogeneity - if provided an empty list, it will compute the heterogeneity \n",
    "                               at each iteration and append it to the list. \n",
    "                               Defaults to None and won't record heterogeneity.\n",
    "      - verbose              - set to True to display progress. Defaults to False and won't \n",
    "                               display progress.\n",
    "\n",
    "    Returns  \n",
    "      - centroids - A np.array of length k for the centroids upon termination of the algorithm.\n",
    "      - cluster_assignment - A np.array of length n where the ith index represents which \n",
    "                             centroid data[i] was assigned to. The assignments range between the \n",
    "                             values 0, ..., k-1 upon termination of the algorithm.\n",
    "    \"\"\"\n",
    "    centroids = initial_centroids[:]\n",
    "    prev_cluster_assignment = None\n",
    "    \n",
    "    for itr in range(max_iter):  \n",
    "        # Print itereation number\n",
    "        if verbose:\n",
    "            print(itr)\n",
    "        \n",
    "        # 1. Make cluster assignments using nearest centroids\n",
    "        cluster_assignment = assign_clusters(data, centroids)\n",
    "            \n",
    "        # 2. Compute a new centroid for each of the k clusters, averaging all data points assigned to that cluster.\n",
    "        centroids = revise_centroids(data, k, cluster_assignment)\n",
    "            \n",
    "        # Check for convergence: if none of the assignments changed, stop\n",
    "        if prev_cluster_assignment is not None and \\\n",
    "          (prev_cluster_assignment == cluster_assignment).all():\n",
    "            break\n",
    "        \n",
    "        # Print number of new assignments \n",
    "        if prev_cluster_assignment is not None:\n",
    "            num_changed = sum(abs(prev_cluster_assignment - cluster_assignment))\n",
    "            if verbose:\n",
    "                print(f'    {num_changed:5d} elements changed their cluster assignment.')  \n",
    "        \n",
    "        # Record heterogeneity convergence metric\n",
    "        if record_heterogeneity is not None:\n",
    "            score = compute_heterogeneity(data, k, centroids, cluster_assignment)\n",
    "            record_heterogeneity.append(score)\n",
    "        \n",
    "        prev_cluster_assignment = cluster_assignment[:]\n",
    "        \n",
    "    return centroids, cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-k9mXeGo2g9"
   },
   "source": [
    "## Plotting convergence metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NLLacWQo2g9"
   },
   "source": [
    "We can use the above function to plot the convergence metric across iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "CKlGRiPro2g9"
   },
   "outputs": [],
   "source": [
    "def plot_heterogeneity(heterogeneity, k):\n",
    "    \"\"\"\n",
    "    Plots how the heterogeneity changes as the number of iterations increases.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(heterogeneity, linewidth=4)\n",
    "    plt.xlabel('# Iterations')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title(f'Heterogeneity of clustering over time, K={k}')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rIUylF3o2g9"
   },
   "source": [
    "Let's consider running k-means with K=3 clusters for a maximum of 400 iterations, recording cluster heterogeneity at every step.  Then, let's plot the heterogeneity over iterations using the plotting function above. We include a seed to ensure everyone gets the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "Cq1dUFcbo2g9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "     2036 elements changed their cluster assignment.\n",
      "2\n",
      "      654 elements changed their cluster assignment.\n",
      "3\n",
      "      376 elements changed their cluster assignment.\n",
      "4\n",
      "      264 elements changed their cluster assignment.\n",
      "5\n",
      "      112 elements changed their cluster assignment.\n",
      "6\n",
      "       37 elements changed their cluster assignment.\n",
      "7\n",
      "       10 elements changed their cluster assignment.\n",
      "8\n",
      "        6 elements changed their cluster assignment.\n",
      "9\n",
      "        2 elements changed their cluster assignment.\n",
      "10\n",
      "        2 elements changed their cluster assignment.\n",
      "11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAELCAYAAADqYO7XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtqklEQVR4nO3deZhcZZn+8e/d3ensK1nIRsIOIQQIHQRxAWSPCgoGlFVU1EF0dEYdZ+anjCPqzIiOy4yCGJZxAxEVZQeVXaADJCSBQICE7Pu+p/v5/XFOd1cVvVR3unJ6uT/XVVefes/21Omufuo85633KCIwMzOz7JRlHYCZmVl352RsZmaWMSdjMzOzjDkZm5mZZczJ2MzMLGNOxmZmZhlzMjZrA0kXSXpgL+3rREmvStos6dxWrHe5pMdLGFrRJM2RdFLWcZRa+js6IOs4rPNxMrZmSVog6dSCtqL/yUu6RtLPSxNddiLiFxFxet1zSSHpoBLt7uvAjyKiX0T8vkT7aFJ7vLaIOCIi/tpOIXUIkv4q6eO5benv6PUMYsl7n0q6UNI6Se9uxTaGSnpC0hpJ6yU9JenE0kRshZyMrUOTVJF1DB3AOGBO1kG0RVf5/UkqzzqGYkm6DPgfYGpEPNKKVTcDVwDDgMHAfwB/7Cq/w47Oydj2mKRRkn4raZWkNyR9Nm0/E/hn4IK0fDczbR8o6WeSlklaIukbdf/s0rPuJyR9T9Ja4Jp0+VvT7S+U9K+SytLlyyVdJ2l1uu/PpGdyFUXu63FJ30nPIt6QdFbO62px3XT60XSVmenrvEDSbEnvy9lWjzTGo5s4hp+QNF/SWkl3SRqVtr8GHEDyT3GzpJ6NrDtW0p3p8Vkj6UeNLDM+97ikbfVndpIOkvSIpA1pnLc19drS9vdKeiE9g3pS0qSc7S6Q9GVJs4Atkipyz9zSasnt6e90k5ISdlXO+pMlPZ/O+42k2yR9o4njVpb+PSyUtDLd5sB03n2SPlOw/ExJH0ynD5P0YHrM50malrPczZJ+LOkeSVuAkwu2cy3wTuBH6XH5UdpeX0VIt/G/ku5Nl3lC0r6S/jv9e3tZ0jE522z0fdQakq4ErgPOiIgnW7NuRGyPiHkRUQsIqCFJykNaG4e1QUT44UeTD2ABcGpB2+XA4+l0GTAD+CpQSZI4Xif5ZwBwDfDzgvV/D1wP9AWGA88An8zZ9m7gaqAC6A3cCvwB6A+MB14BPpYu/ylgLjCG5B/HQ0AAFUXuaxfwCaAc+DSwFFCR6z6e85oCOCjn+ZeA23KenwO82MQxPgVYDUwGegI/BB5t7neQM68cmAl8L42zF/CORn5P43OPS9r2V+Dj6fSvgH9Jf5/122jitU0GVgJvS/d/WRpjz5x4XwDGAr0LXwPJ38R24Ox0/W8Bf0vnVQILgc8BPYAPAjuBbzTx+q8A5pP83fUD7gT+L513KfBEzrITgPXpMe4LLAI+SvJ3Njn9HRyRLnszsAE4se6YNLLv+uPX2LFKt7EaODY9pn8G3kjjKge+AfylmPdRke/T3wIrgKMamb++mcc/FSw7Kz3mAfw06/9B3eWReQB+dOxH+ibfXPDm3UrDP/m3AW8WrPMV4KZ0+hpykjEwAthB+k86bftwzj+ly3O3l/7T2gFMyGn7JPDXdPrPpAkyfX5q+k+kosh9zc+Z1yddd98i120uGY8CNgED0ud3AF9q4hj/DPjPnOf9SD4kjM/5HTSVjE8AVpGTZHPm1cdIy8n4VuAGYEwj2yl8bT8G/r1gmXnAu3PivaKRv6PcZPxQzrwJwLZ0+l3AEtIPRGnb4zSdjB8G/i7n+aHpsasg+fC2BRiXzrsWmJ5OXwA8VrCt64GvpdM3A7e28N6oP36NHat0Gz/NmXc18FLO8yOB9cW8j4p8n24k+dBaVsw6LWyvF8nf+2V7ui0/inu4TG3FODciBtU9gL/LmTcOGJWWK9dLWk9Smh7RxLbGkZzxLMtZ/nqSM886i3Kmh9JwtlRnITA6nR5VsHzudDH7Wl43ERFb08l+Ra7bpIhYCjwBnCdpEHAW8IsmFh+V+/oiYjOwJuc1NmcssDAidhcTVzO+RFKafCYtG1/RzLLjgH8o+J2PJXkddRY1umaD5TnTW4FeaQl9FLAk0oxQxLbyjl06XQGMiIhNwN3Ahem8C2n4HYwD3lbwGi4i+SBW7Gsoxoqc6W2NPO+XE09r3keN+RRwCHCjJLU95PqS9a+Af5J01J5sy4rjC/O2pxYBb0TEwU3ML7wt2CKSM86hzSSQ3HVWk5zpjCMpRwPsR3L2BLCMpERdZ2wr99WUPVm3zi3Ax0neZ09FxJImlltK8voAkNQX2IeG19hSnPtJqmghzi3pzz4kZ1CQk3giYjlJuR5J7wAekvRoRMxvYp/XRsS1zeyvrbeDWwaMlqSchDwWeK2J5fOOHcnfxm4akt6vgK+l1757A39J2xcBj0TEac3E0tJraOtrbExL76NirATeAzwC/C/JZRcg+cpVM+t9MyK+2cS8HiQl85l7EJcVwWfGtqeeATamHXZ6K+lQNVHSlHT+CmC80g5XEbEMeAC4TtKAtAPOgWriKxgRUQPcDlwrqb+kccAXgLqvS90OfE7S6PQM9Ms567ZqXwX7be26K0j+aeX6Pcm1yM+RlIGb8kvgo5KOVtJB65vA0xGxoKU4SY7/MuDbkvpK6qVGvo4SEatIkvvF6e/oCuDAuvmSPiSp7kPNOpJEU9PEa/sp8ClJb1Oir6SpkvoXEW9Lnkr3+xklHb/OAY5rZvlfAZ+XtL+kfiTH7racDyb3kCTrr6fttWn7n4BDJF2ipHNdD0lTJB3eilgb+523VbPvI0knSWox+acVmVOAMyV9L6e9XzOPb6b7OF7SOyRVpjF8meTM/Ol2eo3WDCdj2yNpsnwfcDRJ55TVwI3AwHSR36Q/10h6Lp2+lKT0PJfkH/8dwMhmdnM1yZnd6yTXD38JTE/n/ZQkac4Cnif557ubhkTS2n3las261wC3pCXGaQARsY2kU83+JB2LGhURDwP/L112GUmSvLCp5QvWrTv+BwFvAotJroc25hPAF0lK4EcAub1tpwBPp2dQdwGfi4g3GnttEVGdbutHJMdlPsn16T0WETtJOm19jKR/wsUkiXNHE6tMB/4PeJTk7287yd9L3fZ2kBz7U0n+buraNwGnkxznpSRl8/8g6dxVrO8D56c9o3/QivXeooj30ViSDyrFbGsRSUI+X9K3WhFGT5KvRK0h+eB2NsnXo5a2YhvWRnW9Rs26BCVfTfpJRIxrceG9QNJXgUMi4uKsY+msJD1N8ju9KetYsiLpRuA3EXF/1rFYafiasXVqknqTfAf0AZKS2teA32UaVErSEJIzvEuyjqUzSS8FzCM5O7wImATcl2lQGYuIj7e8lHVmLlNbZyfg30jKpc8DL5F8VzNTkj5B0inn3oh4tKXlLc+hJB2GNgD/AJyfXsM367JcpjYzM8uYz4zNzMwy1mWvGQ8dOjTGjx+fdRhmZmb1ZsyYsToihhW2d9lkPH78eKqrq7MOw8zMrJ6khY21u0xtZmaWMSdjMzOzjDkZm5mZZczJ2MzMLGMlTcaSFkh6UdILkqrTttvS5y+k81/IWf4rkuZLmifpjJz2Y9PtzJf0gz29PZiZmVlHsjd6U58cEavrnkRE/SD2kq4jGWUHSRNIBm0/guQepQ9JOiQdQP3HwJXA30huBHAmcG+pA6+tDZ5ftI57XlzOqYeP4IQD9yn1Ls3MrBvK7KtN6dntNJK7iwCcA/w6vcvKG5LmA8dJWgAMiIin0vVuBc6lxMn47lnL+Pc/zWX5xu0AbNy2y8nYzMxKotTXjAN4QNIMSVcWzHsnsCIiXk2fjyYZy7fO4rRtdDpd2F5SA3v3qE/EAA/MXcGumtpm1jAzM2ubUifjEyNiMnAWcJWkd+XM+zDJjcHrNHYdOJppfwtJV0qqllS9atWqtsYMwPEHDGFwnx71zzds28WTr63Zo22amZk1pqTJuO6m1BGxkuS2dscBSKoguYH4bTmLLya5gXadMSQ3/V6cThe2N7a/GyKiKiKqhg17y2hjrVJRXsYZR+yb13bPLN84xszM2l/JkrGkvpL6100DpwOz09mnAi9HRG75+S7gQkk9Je0PHAw8k946bZOk49PrzJcCfyhV3LnOPnJk3vP75y53qdrMzNpdKc+MRwCPS5oJPAPcHRF1Nwi/kPwSNRExB7gdmEtyI/Gr0p7UAJ8GbgTmA6+xF3pSA5xw4D4MyilVr9+6i7+97lK1mZm1r5L1po6I14Gjmph3eRPt1wLXNtJeDUxsz/iK0aO8jNMnjOD26oYT+HteXM47D96zEriZmVkuj8DVgrMKS9VzlrPbpWozM2tHTsYtOPHAoQzo1VBAWLtlJ8+8sTbDiMzMrKtxMm5BZUUZp03I71V994vuVW1mZu3HybgIUyflJ+P75yynprbRrzqbmZm1mpNxEU48aCj9ezaUqldvdqnazMzaj5NxEXpWlHPahBF5bfe4VG1mZu3EybhIhb2q73Op2szM2omTcZHeefBQ+uWUqldt2kH1ApeqzcxszzkZF6lXj3Lec/jwvLZ7Zy/PKBozM+tKnIxboXCs6ntnL6PWpWozM9tDTsat8O5DhtG3srz++YqNO3juzXUZRmRmZl2Bk3Er9OpRzimH5/eq9gAgZma2p5yMW2nqkfkDgNw3e7lL1WZmtkecjFvp3YcMp3ePhlL1sg3beX7R+uwCMjOzTs/JuJV6V5ZzSmGvapeqzcxsDzgZt8HZEwt7VS8nwqVqMzNrGyfjNjj5sGH06tFw6Jas38bMxRsyjMjMzDozJ+M26FNZwcmH5peqPVa1mZm1lZNxGxUOAHLPi8tcqjYzszZxMm6jUw4bTs+KhsO3eN02XlziUrWZmbWek3Eb9e1ZwUmHDstr8wAgZmbWFk7Ge+AtY1W/6F7VZmbWek7Ge+CUw4ZTmVOqfnPtVuYs3ZhhRGZm1hk5Ge+B/r168K6D80vV7lVtZmat5WS8h6ZOyh+r2r2qzcystZyM99B7Dh9BZXnDYVywZisvLduUYURmZtbZOBnvoQG9evDOg4fmtblUbWZmreFk3A7O8gAgZma2B5yM28FpE0bQo1z1z19fvYV5K1yqNjOz4jgZt4OBvXvwjoMKS9XLM4rGzMw6GyfjdtJYqdrMzKwYTsbt5PQJI6goayhVz1+5mVddqjYzsyI4GbeTQX0qeXtBqdpjVZuZWTGcjNvR1CPfOgCImZlZS5yM29FpE/alPKdU/cqKzcxf6VK1mZk1z8m4HQ3pW8nbD9wnr829qs3MrCVOxu3srInuVW1mZq3jZNzOzjhiBDmVal5evonXV23OLiAzM+vwnIzb2T79enL8Afml6ntnu1RtZmZNczIugbMLBgC5e5ZL1WZm1jQn4xI444h980rVc5dtZMHqLdkFZGZmHZqTcQkM69+T4/Yfktd2z2yfHZuZWeOcjEuksFR9r7/iZGZmTXAyLpEzj9gX5ZSqX1yygTfXbM0uIDMz67CcjEtk+IBeTBmXX6q+16VqMzNrhJNxCZ3tsarNzKwITsYlVHiP45mLN7BorUvVZmaWz8m4hEYM6EXVuMF5bfd5ABAzMyvgZFxibxkAxKVqMzMr4GRcYmcVXDd+YdF6lqzfllE0ZmbWETkZl9jIgb2ZvN+gvLZ7fXZsZmY5nIz3grcMAOLrxmZmlsPJeC8o7FU9Y+E6lm1wqdrMzBJOxnvB6EG9OWrsoLw296o2M7M6TsZ7yVQPAGJmZk1wMt5LzpqYX6quXriOFRu3ZxSNmZl1JEUlY0m/lTRVkpN3G40d0odJYwbWP49wqdrMzBLFJtcfAx8BXpX0bUmHFbOSpAWSXpT0gqTqnParJc2TNEfSf6ZtlZJuSpefKemknOWPTdvnS/qBlHs/pM6j8OzYpWozM4Mik3FEPBQRFwGTgQXAg5KelPRRST1aWP3kiDg6IqoAJJ0MnANMiogjgO+ky30i3deRwGnAdTln4j8GrgQOTh9nFvsCO5LCG0c8s2AtKze5VG1m1t0VXXaWtA9wOfBx4Hng+yTJ+cFW7vPTwLcjYgdARKxM2ycAD+e0rQeqJI0EBkTEUxERwK3Aua3cZ4cwbp++HDFqQP3zCLh/zooMIzIzs46g2GvGdwKPAX2A90XE+yPitoi4GujXzKoBPCBphqQr07ZDgHdKelrSI5KmpO0zgXMkVUjaHzgWGAuMBhbnbHNx2tZYnFdKqpZUvWrVqmJe2l5XOADIPbNcqjYz6+6KPTO+MSImRMS3ImIZgKSeAHXl5yacGBGTgbOAqyS9C6gABgPHA18Ebk+vAU8nSbTVwH8DTwK7gcauD0djO4uIGyKiKiKqhg0bVuRL27sKk/HTb6xh9eYdGUVjZmYdQbHJ+BuNtD3V0koRsTT9uRL4HXAcScK9MxLPALXA0IjYHRGfT68vnwMMAl5Nlx+Ts9kxwNIi4+5w9h/al8NHNpSqawPun+Ne1WZm3VmzyVjSvpKOBXpLOkbS5PRxEknJurl1+0rqXzcNnA7MBn4PnJK2HwJUAqsl9UmXQ9JpwO6ImJueiW+SdHx6Bn0p8Ic2v+IO4OyJHgDEzMwaVLQw/wySTltjgO/mtG8C/rmFdUcAv0u/hVQB/DIi7pNUCUyXNBvYCVwWESFpOHC/pFpgCXBJzrY+DdwM9AbuTR+d1tmTRnLdg6/UP//b62tZs3kH+/TrmWFUZmaWlWaTcUTcAtwi6byI+G1rNhwRrwNHNdK+E7i4kfYFwKFNbKsamNia/XdkBw7rx2H79ufl5ZsAqKkNHpi7gg8ft1/GkZmZWRaaTcaSLo6InwPjJX2hcH5EfLeR1awIZ00cWZ+MISlVOxmbmXVPLXXg6pv+7Af0b+RhbTR1Uv514ydfW8O6LTszisbMzLLUUpn6+vTnv+2dcLqPg4b35+Dh/Xh15WYgKVU/OHcF06aMzTgyMzPb24od9OMQSQ+nna6QNEnSv5Y2tK6v8DvHd7tXtZlZt1Ts94x/CnwF2AUQEbOAC0sVVHdRmIyfmL+aDVt3ZRSNmZllpdhk3CcdoCPX7vYOprs5ZEQ/DhzWt/757trggbkeAMTMrLspNhmvlnQg6TCUks4HXFPdQ5LecnZ8r+9xbGbW7RSbjK8CrgcOk7QE+HuSgThsDxUm48deXcWGbS5Vm5l1J8Xez/j1iDgVGAYcFhHvSAfpsD102L792X9oQ6l6V03w0FzfVtHMrDsptjd1T0kfAT4HfF7SVyV9tbShdQ9JqTr/O8f3zvYVADOz7qTYMvUfgHNIOm1tyXlYOzhrYn6p+tFXVrNxu0vVZmbdRUs3iqgzJiLOLGkk3dgRowYwbp8+LFyzFYCdNbX8+aWVnHvM6IwjMzOzvaHYM+MnJR1Z0ki6MUlvOTv2ACBmZt1Hscn4HcAMSfMkzZL0oqRZpQysu5la0Kv6kVdWsXmHv8ptZtYdFFumPqukURgTRw9gzODeLF63DYCdu2t5+KUVnHO0S9VmZl1dsV9tWgiMBU5Jp7cWu64VR9Jbzo7vfdEDgJiZdQfFfrXpa8CXScanBugB/LxUQXVXhQOA/GXeSra4VG1m1uUVe3b7AeD9pF9nioil+H7G7W7SmIGMHtS7/vmO3bX8Zd7KDCMyM7O9odhkvDMigoaxqfu2sLy1QWMDgNzjXtVmZl1escn4dknXA4MkfQJ4iOS2itbOziosVb+8iq07Xao2M+vKiu3A9R3gDuC3wKHAVyPih6UMrLs6ZuwgRg3sVf98264a/jpvVYYRmZlZqRXdIzoiHoyIL0bEP0bEg6UMqjuTxJkFA4C4VG1m1rUV25t6k6SNBY9Fkn4n6YBSB9ndTJ2Uf934zy+vZPuumoyiMTOzUiv2zPi7wBeB0cAY4B9Jrhn/GphemtC6r2PGDmbfAQ2l6q07a/ire1WbmXVZxSbjMyPi+ojYFBEbI+IG4OyIuA0YXML4uqWyMnHmxMJe1R4AxMysqyo2GddKmiapLH1My5kXpQisuyscAOThl1a4VG1m1kUVm4wvAi4BVqaPS4CLJfUGPlOi2Lq1qnGDGd6/Z/3zLTtrePQV96o2M+uKiv1q0+sR8b6IGJo+3hcR8yNiW0Q8Xuogu6PGS9XuVW1m1hUV25t6TNpzeqWkFZJ+K2lMqYPr7gpL1Q+9tJIdu12qNjPraootU98E3AWMIulR/ce0zUpoyvghDO3XUKrevGM3j72yOsOIzMysFIpNxsMi4qaI2J0+bgaGlTAuA8rLxJkTR+S13TPbpWozs66m2GS8WtLFksrTx8XAmlIGZomzC0bjenDuCpeqzcy6mGKT8RXANGA5sAw4P22zEjtu/yHs07ey/vmm7bt5cr4/B5mZdSUtJmNJ5cA3I+L9ETEsIoZHxLkRsXAvxNftVZSXcfoR+b2q73avajOzLqXFZBwRNcAwSZUtLWulMbWgV/UDc5azc3dtRtGYmVl7qyhyuQXAE5LuArbUNUbEd0sRlOU7/oAhDO7Tg3VbdwGwcftunnxtNScdOjzjyMzMrD0Ue814KfCndPn+OQ/bCyrKyzjjCA8AYmbWVRV1ZhwR/wYgqW9EbGlpeWt/Zx85kl8/u6j++QNzV3BtTS09you+JbWZmXVQxY7AdYKkucBL6fOjJP1vSSOzPCccuA+D+vSof75+6y6ees29qs3MuoJiT6v+GziD9LvFETETeFeJYrJG9Cgv4/QJ+QOA3OsBQMzMuoSia5wRsaigySNP7GVnFfSqvn/OCnbXuFe1mVlnV2wyXiTp7UBIqpT0j6Qla9t7TjxwKAN6NVzmX7tlJ0+/sTbDiMzMrD0Um4w/BVxFcpOIxcDRwN+VKCZrQmVFGadN8AAgZmZdTbHJ+NCIuCgiRqQjcF0MHF7KwKxxUyflJ+P7Zy+npjYyisbMzNpDscn4h0W2WYmdeNBQ+vdsKFWv2bKTGx97PcOIzMxsTzX7PWNJJwBvJxkO8ws5swYA5aUMzBrXs6Kc044YwZ3PLalv+9a9LzN8QE8+cMyYDCMzM7O2aunMuBLoR5K0c0fe2khy5ybLwGdOPoh+PfM/R33xN7N45JVVGUVkZmZ7QhEtX2+UNC4iFnamEbiqqqqiuro66zBK5sn5q7nspmfYVdPw++tTWc6vPnE8R40dlF1gZmbWJEkzIqKqsL3Ya8ajPAJXx/L2g4by3WlH57Vt3VnDR29+ljdWd4rPS2ZmlvIIXJ3Y+44axVffOyGvbe2WnVw6/WlWbtqeUVRmZtZaHoGrk7viHfvzqXcfmNe2aO02Lp/+LJu278ooKjMzaw2PwNUFfPnMQzlvcn5P6rnLNvLJ/5vBjt3+zGRm1tHtyQhcV5UoJmslSXz7vCM5+dBhee1PvraGL9w+k1oPCmJm1qEVlYwjYnXhCFwR4fv3dSA9ysv4n4smc3RBT+q7Zy3j63+aSzG95s3MLBstDfrxQ6DJ/+IR8dl2j8jarE9lBdMvn8L5P3mS11c19Ki++ckFDOvfk6tOPijD6MzMrCktnRlXAzPSx/tzpuse1sEM6VvJrVccx/D+PfPa/+v+edxeXdgHz8zMOoKiBv0AkPR8RBxT4njaTVcf9KMlLy3byLTrn2LT9t31beVl4oZLjuU9h4/IMDIzs+5rTwf9gGbK1c3sdIGkFyW9IKk6p/1qSfMkzZH0n2lbD0m3pMu/JOkrOcsfm7bPl/QDSWptLN3N4SMH8NNLq6isaPgV19QGV/3yOWYsXJdhZGZmVqg1ybitTo6Io+s+CUg6GTgHmBQRRwDfSZf7ENAzIo4EjgU+KWl8Ou/HwJXAwenjzL0Qd6d3/AH78P0Ljib3o8v2XbV87JZnmb9yU3aBmZlZnmaTsaRNkjZK2ghMqpuua2/jPj8NfDsidgBExMq0PYC+kiqA3sBOYKOkkcCAiHgqkpr6rcC5bdx3t3PWkSP5+jkT89rWb93FpT97huUbPEqXmVlH0Gwyjoj+ETEgfVTkTPePiAFFbD+AByTNkHRl2nYI8E5JT0t6RNKUtP0OYAuwDHgT+E5ErKXhu811FqdtbyHpSknVkqpXrfIdjOpccvw4PntKfk/qpRu2c9n0Z9iw1aN0mZllrdRl6hMjYjJwFnCVpHeRfJ1qMHA88EXg9vQa8HEkQ2yOAvYH/kHSAUBj14cbvX4dETdERFVEVA0bNqyxRbqtz592CB8+bmxe27wVm/jErdVs3+VRuszMslTSZBwRS9OfK4HfkSTcxcCdkXgGqAWGAh8B7ouIXenyTwBV6fK5Yz2OAZaWMu6uSBL/fs5ETi3oSf3MgrX8/a9foMajdJmZZaZkyVhSX0n966aB04HZwO+BU9L2Q4BKYDVJafoUJfqSnDm/HBHLgE2Sjk/PoC8F/lCquLuyivIyfvSRY6gaNziv/b45y/nqH2Z7lC4zs4yU8sx4BPC4pJnAM8DdEXEfMB04QNJs4NfAZWnHrP8B+pEk7GeBmyJiVrqtTwM3AvOB14B7Sxh3l9arRzk3XlbFwcP75bX/4uk3+cHD8zOKysyseyt60I/OprsP+tGSpeu3cd6Pn2RZQY/qb37gSD7ytv0yisrMrGtrj0E/rAsZNag3t1xxHAN65Q9P/q+/f5H75yzPKCozs+7JybgbO2REf6ZfPoWeOaN01QZ89lfP8+yCtRlGZmbWvTgZd3NV44fwo49MpiznC2Q7dtfysZufZd5yj9JlZrY3OBkbp00YwTc/cGRe28btu7ls+jMsWb8to6jMzLoPJ2MD4MLj9uMLpx2S17Z8YzJK1/qtOzOKysyse3AytnpXn3IQlxw/Lq9t/srNXHHzs2zb6VG6zMxKxcnY6knimvcfwVkT981rf+7N9Xzml8+xu6Y2o8jMzLo2J2PLU14mvnfB0bxt/yF57Q+/vJJ//t2LHqXLzKwEnIztLXr1KOeGS6s4bN/+ee23Vy/mugdeySgqM7Ouy8nYGjWwdw9uueI4Rg/qndf+o7/M55YnF2QTlJlZF+VkbE0aMaAXt37sOAb36ZHXfs0f53D3rGUZRWVm1vU4GVuzDhzWj+mXT6F3j/L6tgj4/G0v8ORrqzOMzMys63AythYds99g/vfiyZTnDNO1s6aWT946g7lLN2YYmZlZ1+BkbEU5+dDh/Md5k/LaNu3YzWU3PcOitVszisrMrGtwMrainX/sGL585mF5bas27eDS6c+wZvOOjKIyM+v8nIytVT717gP46Inj89reWL2FK26pZuvO3dkEZWbWyTkZW6tI4v9NncB7J43Ma5+5aD1/94vn2OVRuszMWs3J2FqtrExcN+0oTjxon7z2v85bxZd/O8ujdJmZtZKTsbVJz4pyfnLxsRwxakBe+53PLeHb972cUVRmZp2Tk7G1Wf9ePbjpo1MYOyR/lK7rH3mdnz3+RkZRmZl1Pk7GtkeG9+/F/13xNvbpW5nX/u9/msvHb3mW++cs93VkM7MWqKte36uqqorq6uqsw+g2Zi1ez4U3/I2tjdz3eGi/Sj44eQzTqsZy0PB+GURnZtYxSJoREVVvaXcytvby6CuruOLmZ9ld2/Tf1LHjBjOtagxTJ42iX8+KvRidmVn2nIxtr3hy/mr+7Y9zmbdiU7PL9aksZ+qRI5k2ZSxV4wYjqdnlzcy6Aidj22siglmLN3Bb9SL++MJSNu1ofjCQA4b25UNVYznv2NEM799rL0VpZrb3ORlbJrbtrOHe2cu4vXoRf3t9bbPLlpeJkw8dzrSqMZx82HB6lLt/oZl1LU7GlrkFq7dwx4zF3DFjMcs3bm922aH9enLe5NF8yJ2+zKwLcTK2DqOmNnj01VXc/uwiHnppBbtqmv8bPHbcYC6oGsvUSSPp605fZtaJORlbh7Rm8w5+9/wSbq9exCsrNje7bJ/Kct47aSTTqsZyrDt9mVkn5GRsHVpEMHPxBm4vttPXsL5MqxrLBye705eZdR5OxtZp1HX6uu3ZRTz9RnGdvi6YMpaTDh3mTl9m1qE5GVuntGD1Fn4zYxF3zFjMio07ml12WP+efHDyaKZVjeXAYe70ZWYdj5OxdWo1tcGjr6zi9uriOn1VjRvMNHf6MrMOxsnYuoy2dPq6YMpYJu/nTl9mli0nY+ty6jp93fbsIv44cymbW+j0dWDa6eukQ4dz8PB+lJU5MZvZ3uVkbF3atp013PNiMtJXS52+AAb0quDYcYOpGj+EqnGDOWrsIHr1KN8LkZpZd+ZkbN1Gazp91elRLiaOHsiU8UOSJD1uMPv061niSM2su3Eytm5nd00tj726mtvSkb6au7VjYw4Y2peq8Q1nz/sP7etrzma2R5yMrVtbs3kHv39hKU/MX031grVs3N789eXG7NO3Mi1tJwl64qiBVFb4e81mVjwnY7NUbW0wf9Vmnl2wlhkL1vHswrUsWrut1dvpWVHGUWMHUTVuMFPGD2HyfoMZ2KdHCSI2s67CydisGSs2bqd6wTqqF66lesE65i7bSE0ry9oSHDK8P8eOH8yU8YOpGjeEMYN7u7RtZvWcjM1aYcuO3bywaH19gn5u4Tq27Kxp9XZGDOhJ1bghVI1Pzp4P27c/FR6y06zbcjI22wO7a2p5efkmZixcx7MLkrPnlu7J3Jg+leUcs9+g+gR9zH6D6ecRwsy6DSdjs3YUESxZvy0vOc9bsYnWvp3KBIePHFB/1jxyUG9GD+rFyIG9PYynWRfkZGxWYhu27eK5N9clncIWrGXm4vVs31Xb5u0N6FXBqEG9GTWoNyMH9kqnk0Q9elBvRgzo5d7cZp2Mk7HZXrZzdy1zlm6oP3uesXAdqzfvbLftSzC0X88kSQ9MkvSoQb3qk/foQb0Z2q+nh/0060CcjM0yFhEsXLO1vqxdvXAtr63aUtJ99igXIwb0akjY6c8kYSfJe2DvHu7xbbaXNJWMfVHKbC+RxPihfRk/tC8fqhoLwNotO5mxcB0zF61nyfptLFm/jWUbtrF8w/YWbxNZjF01weJ121i8runvUfepLG8ogw/szchBvRg1MC2PD+rF0H49KS8T5RISlEmUl4ky4SRu1k58ZmzWAdXWBqs372Dphu0sq0/S21m2YRtL1idtqzbvaHWHsfZWn5wLErVEmrDrHk3No2GZNMEny4jyvHm56zfMy/8soPqY8lsK2xqe1LU3Or/R7aiRtrcuV7hs4bzmGtVIY2OfeQqbGl+muG21pG2fuVq3Uls/17Vltbbs632TRvG2A/Zpw94K9+0zY7NOo6xMDB/Qi+EDenH02EGNLrNzdy0rNm5n6fptLN2wjaXrk2S9dH3StmzDdjZs21XSOCOgJoIauuaHerM6h47o3y7JuClOxmadVGVFGWOH9GHskD5NLrNlx+68BF13pr10wzaWrd/O0g3b9qjHt5m1Dydjsy6sb88KDhren4OG9290fkSwbuuu+jPppbmJOufsujYiedRCbQQ1EZmXyM26Eidjs25MEkP6VjKkbyUTRw9s1bqRJuSaxhJ1znTevNpknYaEHtSk896a7FuelxsLkFcsb/iwEG9pa3w5iHROflv+PvKPwVvXLWxv7HlhDA3LNbKPRpYrbIxGlip2ny1py4euxuJp730k+2nLSm3b2ZT9h7RpvWI5GZtZm6iu01abutCYWS4P32NmZpYxJ2MzM7OMORmbmZllzMnYzMwsY07GZmZmGXMyNjMzy1iXHZta0ipgYTttbiiwup221V34mLWej1nr+Zi1no9Z67T38RoXEcMKG7tsMm5PkqobG9jbmuZj1no+Zq3nY9Z6Pmats7eOl8vUZmZmGXMyNjMzy5iTcXFuyDqATsjHrPV8zFrPx6z1fMxaZ68cL18zNjMzy5jPjM3MzDLmZGxmZpYxJ+NmSDpT0jxJ8yX9U9bxdHSSxkr6i6SXJM2R9LmsY+osJJVLel7Sn7KOpTOQNEjSHZJeTv/eTsg6po5O0ufT9+VsSb+S1CvrmDoaSdMlrZQ0O6dtiKQHJb2a/hxcin07GTdBUjnwP8BZwATgw5ImZBtVh7cb+IeIOBw4HrjKx6xonwNeyjqITuT7wH0RcRhwFD52zZI0GvgsUBURE4Fy4MJso+qQbgbOLGj7J+DhiDgYeDh93u6cjJt2HDA/Il6PiJ3Ar4FzMo6pQ4uIZRHxXDq9ieQf5Ohso+r4JI0BpgI3Zh1LZyBpAPAu4GcAEbEzItZnGlTnUAH0llQB9AGWZhxPhxMRjwJrC5rPAW5Jp28Bzi3Fvp2MmzYaWJTzfDFOLEWTNB44Bng641A6g/8GvgTUZhxHZ3EAsAq4KS3t3yipb9ZBdWQRsQT4DvAmsAzYEBEPZBtVpzEiIpZBcsIBDC/FTpyMm6ZG2vw9sCJI6gf8Fvj7iNiYdTwdmaT3AisjYkbWsXQiFcBk4McRcQywhRKVDruK9DrnOcD+wCigr6SLs43KcjkZN20xMDbn+Rhc1mmRpB4kifgXEXFn1vF0AicC75e0gORSyCmSfp5tSB3eYmBxRNRVXe4gSc7WtFOBNyJiVUTsAu4E3p5xTJ3FCkkjAdKfK0uxEyfjpj0LHCxpf0mVJJ0d7so4pg5Nkkiu470UEd/NOp7OICK+EhFjImI8yd/YnyPCZyzNiIjlwCJJh6ZN7wHmZhhSZ/AmcLykPun79D2401ux7gIuS6cvA/5Qip1UlGKjXUFE7Jb0GeB+kp6H0yNiTsZhdXQnApcAL0p6IW3754i4J7uQrIu6GvhF+kH5deCjGcfToUXE05LuAJ4j+dbD83hYzLeQ9CvgJGCopMXA14BvA7dL+hjJh5oPlWTfHg7TzMwsWy5Tm5mZZczJ2MzMLGNOxmZmZhlzMjYzM8uYk7GZmVnGnIzNOilJ35J0kqRzm7qrmKRrJP1jOn25pFHtuP+TJL095/mnJF3aXts3606cjM06r7eRjP39buCxIpa/nGQoxKKlNxVoyknkjOIUET+JiFtbs30zS/h7xmadjKT/As4gGWf4NeBA4A3gjoj4esGy1wCbgQUkt4dbAmwDTiC5Neh3gX7AauDyiFgm6a/AkySDuNwFvAL8K1AJrAEuAnoDfwNqSG7acDXJqE6bI+I7ko4GfkJyd6DXgCsiYl267aeBk4FBwMci4jFJRwA3pfsoA86LiFfb5YCZdQI+MzbrZCLii8DHSZLrFGBWREwqTMQF69wBVAMXRcTRJKMw/RA4PyKOBaYD1+asMigi3h0R1wGPA8enN2X4NfCliFhAkmy/FxFHR0ThmfmtwJcjYhLwIslIRnUqIuI44O9z2j8FfD+NrYpk/GmzbsPDYZp1TscALwCH0bZxmQ8FJgIPJkMVU05ya706t+VMjwFuSwfJryQ5C2+SpIEkyfyRtOkW4Dc5i9TdQGQGMD6dfgr4l/Teznf6rNi6Gydjs04kLf/eTJIgV5OUgZWOBX5CRGwrdlPAnIg4oYn5W3Kmfwh8NyLuknQScE1r4y6wI/1ZQ/o/KCJ+KelpYCpwv6SPR8Sf93A/Zp2Gy9RmnUhEvJCWcl8hueb7Z+CMtFTcUiLeBPRPp+cBwySdAMmtL9Prto0ZSHKtGRruXlO4vdwYNwDrJL0zbboEeKRwuVySDgBej4gfkFynntTCazHrUpyMzToZScOAdRFRCxwWEcWWqW8GfpKeRZcD5wP/IWkmScm7qfvbXgP8RtJjJGfjdf4IfEDSCzmJt85lwH9JmgUcDTR5PTt1ATA7je0wkmvOZt2Ge1ObmZllzGfGZmZmGXMyNjMzy5iTsZmZWcacjM3MzDLmZGxmZpYxJ2MzM7OMORmbmZll7P8DmKoADzIJQEUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 3\n",
    "heterogeneity = []\n",
    "initial_centroids = get_initial_centroids(tf_idf, k, seed=0)\n",
    "centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, max_iter=400,\n",
    "                                       record_heterogeneity=heterogeneity, verbose=True)\n",
    "plot_heterogeneity(heterogeneity, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySIw0ENho2g-"
   },
   "source": [
    "### üîç **Question 6** Largest cluster\n",
    "\n",
    "Using the clustering made in the last cell, write code to computer which cluster contains the most data points. Store your result as a index (an `int`) in a variable named `largest_cluster` \n",
    "representing which cluster in `centroids` has the most datapoints assigned to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "LD169iTdo2g-"
   },
   "outputs": [],
   "source": [
    "### edTest(test_q6_largest_cluster) ###\n",
    "\n",
    "# TODO Find largest cluster from example above\n",
    "largest_cluster = np.argmax(cluster_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRMReDFDo2g-"
   },
   "source": [
    "# Beware of Local Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFTr3iT1o2g-"
   },
   "source": [
    "One weakness of k-means is that it tends to get stuck in a local minimum based on its starting position. To see this, let us run k-means multiple times, with different initial centroids created using different random seeds.\n",
    "\n",
    "**Note:** Again, in practice, you should set different seeds for every run. We give you a list of seeds for this assignment so that everyone gets the same answer.\n",
    "\n",
    "This may take a minute or two to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "GYoNAOYWo2g-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=5569.17352\n",
      "seed=020000, heterogeneity=5563.93396\n",
      "seed=040000, heterogeneity=5562.09533\n",
      "seed=060000, heterogeneity=5574.80813\n",
      "seed=080000, heterogeneity=5563.38377\n",
      "seed=100000, heterogeneity=5565.93209\n",
      "seed=120000, heterogeneity=5572.40064\n",
      "CPU times: user 3.18 s, sys: 38.9 ms, total: 3.22 s\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ^ Magic command to time how long it takes for this cell to run!\n",
    "# You can see how long it took with the output that says \"Wall time\"\n",
    "\n",
    "k = 10\n",
    "heterogeneity = {}\n",
    "for seed in [0, 20000, 40000, 60000, 80000, 100000, 120000]:\n",
    "    initial_centroids = get_initial_centroids(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, max_iter=800,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "    print(f'seed={seed:06d}, heterogeneity={heterogeneity[seed]:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LJPdfM5o2g_"
   },
   "source": [
    "Notice the variation in heterogeneity for different initializations. This indicates that k-means runs may have not converged or they got stuck at a local minimum.\n",
    "\n",
    "# k-means++\n",
    "One effective way to counter this tendency is to use **k-means++** to provide a smart initialization. This method tries to spread out the initial set of centroids so that they are not too close together. It is known to improve the quality of local optima and lower average runtime, but is a bit slower to start since it needs to do more computation to place centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "grD3A8E7o2g_"
   },
   "outputs": [],
   "source": [
    "def smart_initialize(data, k, seed=None):\n",
    "    \"\"\"\n",
    "    Use k-means++ to initialize a good set of centroids\n",
    "    \"\"\"\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    centroids = np.zeros((k, data.shape[1]))\n",
    "    \n",
    "    # Randomly choose the first centroid.\n",
    "    # Since we have no prior knowledge, choose uniformly at random\n",
    "    idx = np.random.randint(data.shape[0])\n",
    "    centroids[0] = data[idx,:].toarray()\n",
    "    \n",
    "    # Compute distances from the first centroid chosen to all the other data points\n",
    "    distances = pairwise_distances(data, centroids[0:1], metric='euclidean').flatten()\n",
    "    \n",
    "    for i in range(1, k):\n",
    "        # Choose the next centroid randomly, so that the probability for each data point to be chosen\n",
    "        # is directly proportional to its squared distance from the nearest centroid.\n",
    "        # Roughtly speaking, a new centroid should be as far as from ohter centroids as possible.\n",
    "        idx = np.random.choice(data.shape[0], 1, p=distances/sum(distances))\n",
    "        centroids[i] = data[idx,:].toarray()\n",
    "        \n",
    "        # Now compute distances from the centroids to all data points\n",
    "        distances = np.min(pairwise_distances(data, centroids[0:i+1], metric='euclidean'),axis=1)\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngnC2CyZo2g_"
   },
   "source": [
    "Let's now rerun k-means with 10 clusters using the same set of seeds, but always using k-means++ to initialize the algorithm.\n",
    "\n",
    "This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "ul1EL9Kco2g_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=5563.24947\n",
      "seed=020000, heterogeneity=5569.53006\n",
      "seed=040000, heterogeneity=5563.95996\n",
      "seed=060000, heterogeneity=5567.74848\n",
      "seed=080000, heterogeneity=5557.53663\n",
      "seed=100000, heterogeneity=5559.45113\n",
      "seed=120000, heterogeneity=5559.02003\n",
      "CPU times: user 3.57 s, sys: 28.3 ms, total: 3.6 s\n",
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "heterogeneity_smart = {}\n",
    "for seed in [0, 20000, 40000, 60000, 80000, 100000, 120000]:\n",
    "    initial_centroids = smart_initialize(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, max_iter=400,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity_smart[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "    print(f'seed={seed:06d}, heterogeneity={heterogeneity_smart[seed]:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlFP9d2zo2g_"
   },
   "source": [
    "Let's compare the set of cluster heterogeneities we got from our 7 restarts of k-means using random initialization compared to the 7 restarts of k-means using k-means++ as a smart initialization.\n",
    "\n",
    "The following code produces a [box plot](http://matplotlib.org/api/pyplot_api.html) for each of these methods, indicating the spread of values produced by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "_xQV241Eo2g_"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.boxplot([list(heterogeneity.values()), list(heterogeneity_smart.values())], vert=False)\n",
    "\n",
    "plt.yticks([1, 2], ['k-means', 'k-means++'])\n",
    "plt.xlabel('Heterogeneity')\n",
    "plt.title('Heterogeneity distribution of k-means vs k-means++')\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVskmXloo2hA"
   },
   "source": [
    "A few things to notice from the box plot:\n",
    "* Random initialization results in a worse clustering than k-means++ on average.\n",
    "* The best result of k-means++ is better than the best result of random initialization.\n",
    "\n",
    "## üîç **Question 7** kmeans_multiple_runs\n",
    "**In general, you should run k-means at least a few times with different initializations and then return the run resulting in the lowest heterogeneity.** Let us write a function that runs k-means multiple times and picks the best run that minimizes heterogeneity.\n",
    "\n",
    "Now we are ready to fill in the blanks the function `kmeans_multiple_runs(data, k, max_iter, verbose=False)`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "wH93hy8Uo2hA"
   },
   "outputs": [],
   "source": [
    "### edTest(test_q7_kmeans_multiple_runs) ###\n",
    "\n",
    "# TODO Fill in the ...\n",
    "def kmeans_multiple_runs(data, k, max_iter, seeds, verbose=False):\n",
    "    \"\"\"\n",
    "    Runs kmeans multiple times \n",
    "    \n",
    "    Parameters:  \n",
    "      - data     - is an np.array of float values of length n.\n",
    "      - k        - number of centroids\n",
    "      - max_iter - maximum number of iterations to run the algorithm\n",
    "      - seeds    - Either number of seeds to try (generated randomly) or a list of seed values\n",
    "      - verbose  - set to True to display progress. Defaults to False and won't display progress.\n",
    "    \n",
    "    Returns  \n",
    "      - final_centroids          - A np.array of length k for the centroids upon \n",
    "                                   termination of the algorithm.\n",
    "      - final_cluster_assignment - A np.array of length n where the ith index represents which \n",
    "                                   centroid data[i] was assigned to. The assignments range between \n",
    "                                   the values 0, ..., k-1 upon termination of the algorithm.\n",
    "    \"\"\"    \n",
    "    min_heterogeneity_achieved = float('inf')\n",
    "    final_centroids = None\n",
    "    final_cluster_assignment = None\n",
    "    if type(seeds) == int:\n",
    "        seeds = np.random.randint(low=0, high=10000, size=seeds)\n",
    "    \n",
    "    num_runs = len(seeds)\n",
    "    \n",
    "    for seed in seeds:\n",
    "        # Use k-means++ initialization: Fill in the blank\n",
    "        # Set record_heterogeneity=None because we will compute that once at the end.\n",
    "        initial_centroids = smart_initialize(data, k, seed=None)\n",
    "\n",
    "        # Run k-means: Fill in the blank \n",
    "        centroids, cluster_assignment = kmeans(data, k, initial_centroids, max_iter=max_iter, record_heterogeneity=None, verbose=verbose)\n",
    "        \n",
    "        # To save time, compute heterogeneity only once in the end\n",
    "        seed_heterogeneity = compute_heterogeneity(data, k, centroids, cluster_assignment)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'seed={seed:06d}, heterogeneity={seed_heterogeneity:.5f}')\n",
    "        \n",
    "        # if current measurement of heterogeneity is lower than previously seen,\n",
    "        # update the minimum record of heterogeneity.\n",
    "        if seed_heterogeneity < min_heterogeneity_achieved:\n",
    "            min_heterogeneity_achieved = seed_heterogeneity\n",
    "            final_centroids = centroids\n",
    "            final_cluster_assignment = cluster_assignment\n",
    "    \n",
    "    # Return the centroids and cluster assignments that minimize heterogeneity.\n",
    "    return final_centroids, final_cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1dX6FT1o2hA"
   },
   "source": [
    "## How to choose K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB4_wTKso2hA"
   },
   "source": [
    "Since we are measuring the tightness of the clusters, a higher value of K reduces the possible heterogeneity metric by definition.  For example, if we have N data points and set K=N clusters, then we could have 0 cluster heterogeneity by setting the N centroids equal to the values of the N data points. (Note: Not all runs for larger K will result in lower heterogeneity than a single run with smaller K due to local optima.)  Let's explore this general trend for ourselves by performing the following analysis.\n",
    "\n",
    "\n",
    "This code block will take some times to complete. It will try 5 values of `k` and for each `k`, will try 3 different seeds. The cell will print its progress to help you know how far it has made. When `k` is larger, it will take longer to run (why might that be?)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "Iq_wCe8Vo2hA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running k = 2\n",
      "0\n",
      "1\n",
      "      642 elements changed their cluster assignment.\n",
      "2\n",
      "      763 elements changed their cluster assignment.\n",
      "3\n",
      "       58 elements changed their cluster assignment.\n",
      "4\n",
      "        2 elements changed their cluster assignment.\n",
      "5\n",
      "seed=020000, heterogeneity=5668.36228\n",
      "0\n",
      "1\n",
      "     1351 elements changed their cluster assignment.\n",
      "2\n",
      "      334 elements changed their cluster assignment.\n",
      "3\n",
      "      121 elements changed their cluster assignment.\n",
      "4\n",
      "       60 elements changed their cluster assignment.\n",
      "5\n",
      "       33 elements changed their cluster assignment.\n",
      "6\n",
      "       18 elements changed their cluster assignment.\n",
      "7\n",
      "       20 elements changed their cluster assignment.\n",
      "8\n",
      "       24 elements changed their cluster assignment.\n",
      "9\n",
      "       20 elements changed their cluster assignment.\n",
      "10\n",
      "       24 elements changed their cluster assignment.\n",
      "11\n",
      "       14 elements changed their cluster assignment.\n",
      "12\n",
      "       14 elements changed their cluster assignment.\n",
      "13\n",
      "       11 elements changed their cluster assignment.\n",
      "14\n",
      "        7 elements changed their cluster assignment.\n",
      "15\n",
      "        9 elements changed their cluster assignment.\n",
      "16\n",
      "       12 elements changed their cluster assignment.\n",
      "17\n",
      "       10 elements changed their cluster assignment.\n",
      "18\n",
      "       12 elements changed their cluster assignment.\n",
      "19\n",
      "       17 elements changed their cluster assignment.\n",
      "20\n",
      "       14 elements changed their cluster assignment.\n",
      "21\n",
      "       15 elements changed their cluster assignment.\n",
      "22\n",
      "       15 elements changed their cluster assignment.\n",
      "23\n",
      "       19 elements changed their cluster assignment.\n",
      "24\n",
      "       27 elements changed their cluster assignment.\n",
      "25\n",
      "       28 elements changed their cluster assignment.\n",
      "26\n",
      "       29 elements changed their cluster assignment.\n",
      "27\n",
      "       35 elements changed their cluster assignment.\n",
      "28\n",
      "       46 elements changed their cluster assignment.\n",
      "29\n",
      "       68 elements changed their cluster assignment.\n",
      "30\n",
      "       89 elements changed their cluster assignment.\n",
      "31\n",
      "      135 elements changed their cluster assignment.\n",
      "32\n",
      "      157 elements changed their cluster assignment.\n",
      "33\n",
      "      177 elements changed their cluster assignment.\n",
      "34\n",
      "      188 elements changed their cluster assignment.\n",
      "35\n",
      "      161 elements changed their cluster assignment.\n",
      "36\n",
      "      167 elements changed their cluster assignment.\n",
      "37\n",
      "      217 elements changed their cluster assignment.\n",
      "38\n",
      "      260 elements changed their cluster assignment.\n",
      "39\n",
      "      297 elements changed their cluster assignment.\n",
      "40\n",
      "      271 elements changed their cluster assignment.\n",
      "41\n",
      "       81 elements changed their cluster assignment.\n",
      "42\n",
      "       22 elements changed their cluster assignment.\n",
      "43\n",
      "        6 elements changed their cluster assignment.\n",
      "44\n",
      "        1 elements changed their cluster assignment.\n",
      "45\n",
      "seed=040000, heterogeneity=5668.36228\n",
      "0\n",
      "1\n",
      "      649 elements changed their cluster assignment.\n",
      "2\n",
      "      173 elements changed their cluster assignment.\n",
      "3\n",
      "      137 elements changed their cluster assignment.\n",
      "4\n",
      "      158 elements changed their cluster assignment.\n",
      "5\n",
      "      167 elements changed their cluster assignment.\n",
      "6\n",
      "      144 elements changed their cluster assignment.\n",
      "7\n",
      "       94 elements changed their cluster assignment.\n",
      "8\n",
      "       60 elements changed their cluster assignment.\n",
      "9\n",
      "       52 elements changed their cluster assignment.\n",
      "10\n",
      "       37 elements changed their cluster assignment.\n",
      "11\n",
      "       26 elements changed their cluster assignment.\n",
      "12\n",
      "       15 elements changed their cluster assignment.\n",
      "13\n",
      "        6 elements changed their cluster assignment.\n",
      "14\n",
      "        3 elements changed their cluster assignment.\n",
      "15\n",
      "        3 elements changed their cluster assignment.\n",
      "16\n",
      "        4 elements changed their cluster assignment.\n",
      "17\n",
      "        6 elements changed their cluster assignment.\n",
      "18\n",
      "        7 elements changed their cluster assignment.\n",
      "19\n",
      "        4 elements changed their cluster assignment.\n",
      "20\n",
      "        4 elements changed their cluster assignment.\n",
      "21\n",
      "        4 elements changed their cluster assignment.\n",
      "22\n",
      "        3 elements changed their cluster assignment.\n",
      "23\n",
      "        1 elements changed their cluster assignment.\n",
      "24\n",
      "        2 elements changed their cluster assignment.\n",
      "25\n",
      "        2 elements changed their cluster assignment.\n",
      "26\n",
      "        2 elements changed their cluster assignment.\n",
      "27\n",
      "seed=080000, heterogeneity=5687.79459\n",
      "Running k = 10\n",
      "0\n",
      "1\n",
      "     5750 elements changed their cluster assignment.\n",
      "2\n",
      "     1517 elements changed their cluster assignment.\n",
      "3\n",
      "     1027 elements changed their cluster assignment.\n",
      "4\n",
      "      873 elements changed their cluster assignment.\n",
      "5\n",
      "      624 elements changed their cluster assignment.\n",
      "6\n",
      "      531 elements changed their cluster assignment.\n",
      "7\n",
      "      399 elements changed their cluster assignment.\n",
      "8\n",
      "      337 elements changed their cluster assignment.\n",
      "9\n",
      "      305 elements changed their cluster assignment.\n",
      "10\n",
      "      237 elements changed their cluster assignment.\n",
      "11\n",
      "      134 elements changed their cluster assignment.\n",
      "12\n",
      "       73 elements changed their cluster assignment.\n",
      "13\n",
      "       45 elements changed their cluster assignment.\n",
      "14\n",
      "       32 elements changed their cluster assignment.\n",
      "15\n",
      "       49 elements changed their cluster assignment.\n",
      "16\n",
      "       44 elements changed their cluster assignment.\n",
      "17\n",
      "       37 elements changed their cluster assignment.\n",
      "18\n",
      "       30 elements changed their cluster assignment.\n",
      "19\n",
      "       45 elements changed their cluster assignment.\n",
      "20\n",
      "       33 elements changed their cluster assignment.\n",
      "21\n",
      "       40 elements changed their cluster assignment.\n",
      "22\n",
      "       29 elements changed their cluster assignment.\n",
      "23\n",
      "       27 elements changed their cluster assignment.\n",
      "24\n",
      "       22 elements changed their cluster assignment.\n",
      "25\n",
      "       13 elements changed their cluster assignment.\n",
      "26\n",
      "        9 elements changed their cluster assignment.\n",
      "27\n",
      "        3 elements changed their cluster assignment.\n",
      "28\n",
      "seed=020000, heterogeneity=5571.45755\n",
      "0\n",
      "1\n",
      "     6602 elements changed their cluster assignment.\n",
      "2\n",
      "     3093 elements changed their cluster assignment.\n",
      "3\n",
      "     1792 elements changed their cluster assignment.\n",
      "4\n",
      "      897 elements changed their cluster assignment.\n",
      "5\n",
      "      892 elements changed their cluster assignment.\n",
      "6\n",
      "      710 elements changed their cluster assignment.\n",
      "7\n",
      "      827 elements changed their cluster assignment.\n",
      "8\n",
      "      941 elements changed their cluster assignment.\n",
      "9\n",
      "      842 elements changed their cluster assignment.\n",
      "10\n",
      "      674 elements changed their cluster assignment.\n",
      "11\n",
      "      632 elements changed their cluster assignment.\n",
      "12\n",
      "      692 elements changed their cluster assignment.\n",
      "13\n",
      "      624 elements changed their cluster assignment.\n",
      "14\n",
      "      443 elements changed their cluster assignment.\n",
      "15\n",
      "      241 elements changed their cluster assignment.\n",
      "16\n",
      "      164 elements changed their cluster assignment.\n",
      "17\n",
      "       69 elements changed their cluster assignment.\n",
      "18\n",
      "       95 elements changed their cluster assignment.\n",
      "19\n",
      "       69 elements changed their cluster assignment.\n",
      "20\n",
      "       45 elements changed their cluster assignment.\n",
      "21\n",
      "       21 elements changed their cluster assignment.\n",
      "22\n",
      "       17 elements changed their cluster assignment.\n",
      "23\n",
      "seed=040000, heterogeneity=5566.88974\n",
      "0\n",
      "1\n",
      "     6967 elements changed their cluster assignment.\n",
      "2\n",
      "     1895 elements changed their cluster assignment.\n",
      "3\n",
      "      923 elements changed their cluster assignment.\n",
      "4\n",
      "      864 elements changed their cluster assignment.\n",
      "5\n",
      "      781 elements changed their cluster assignment.\n",
      "6\n",
      "      642 elements changed their cluster assignment.\n",
      "7\n",
      "      443 elements changed their cluster assignment.\n",
      "8\n",
      "      237 elements changed their cluster assignment.\n",
      "9\n",
      "      159 elements changed their cluster assignment.\n",
      "10\n",
      "      113 elements changed their cluster assignment.\n",
      "11\n",
      "       69 elements changed their cluster assignment.\n",
      "12\n",
      "       55 elements changed their cluster assignment.\n",
      "13\n",
      "       50 elements changed their cluster assignment.\n",
      "14\n",
      "       34 elements changed their cluster assignment.\n",
      "15\n",
      "        7 elements changed their cluster assignment.\n",
      "16\n",
      "       18 elements changed their cluster assignment.\n",
      "17\n",
      "seed=080000, heterogeneity=5555.18245\n",
      "Running k = 25\n",
      "0\n",
      "1\n",
      "    14344 elements changed their cluster assignment.\n",
      "2\n",
      "     6809 elements changed their cluster assignment.\n",
      "3\n",
      "     3737 elements changed their cluster assignment.\n",
      "4\n",
      "     2311 elements changed their cluster assignment.\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1442 elements changed their cluster assignment.\n",
      "6\n",
      "      793 elements changed their cluster assignment.\n",
      "7\n",
      "      609 elements changed their cluster assignment.\n",
      "8\n",
      "      272 elements changed their cluster assignment.\n",
      "9\n",
      "      161 elements changed their cluster assignment.\n",
      "10\n",
      "      125 elements changed their cluster assignment.\n",
      "11\n",
      "       88 elements changed their cluster assignment.\n",
      "12\n",
      "        7 elements changed their cluster assignment.\n",
      "13\n",
      "seed=020000, heterogeneity=5483.23626\n",
      "0\n",
      "1\n",
      "    13760 elements changed their cluster assignment.\n",
      "2\n",
      "     4623 elements changed their cluster assignment.\n",
      "3\n",
      "     2859 elements changed their cluster assignment.\n",
      "4\n",
      "     2285 elements changed their cluster assignment.\n",
      "5\n",
      "     2120 elements changed their cluster assignment.\n",
      "6\n",
      "     1619 elements changed their cluster assignment.\n",
      "7\n",
      "     1199 elements changed their cluster assignment.\n",
      "8\n",
      "     1043 elements changed their cluster assignment.\n",
      "9\n",
      "      884 elements changed their cluster assignment.\n",
      "10\n",
      "      698 elements changed their cluster assignment.\n",
      "11\n",
      "      570 elements changed their cluster assignment.\n",
      "12\n",
      "      615 elements changed their cluster assignment.\n",
      "13\n",
      "      487 elements changed their cluster assignment.\n",
      "14\n",
      "      427 elements changed their cluster assignment.\n",
      "15\n",
      "      230 elements changed their cluster assignment.\n",
      "16\n",
      "      277 elements changed their cluster assignment.\n",
      "17\n",
      "      257 elements changed their cluster assignment.\n",
      "18\n",
      "      180 elements changed their cluster assignment.\n",
      "19\n",
      "      201 elements changed their cluster assignment.\n",
      "20\n",
      "      149 elements changed their cluster assignment.\n",
      "21\n",
      "      126 elements changed their cluster assignment.\n",
      "22\n",
      "       97 elements changed their cluster assignment.\n",
      "23\n",
      "      100 elements changed their cluster assignment.\n",
      "24\n",
      "       49 elements changed their cluster assignment.\n",
      "25\n",
      "       21 elements changed their cluster assignment.\n",
      "26\n",
      "       16 elements changed their cluster assignment.\n",
      "27\n",
      "        7 elements changed their cluster assignment.\n",
      "28\n",
      "       19 elements changed their cluster assignment.\n",
      "29\n",
      "seed=040000, heterogeneity=5490.83976\n",
      "0\n",
      "1\n",
      "    10101 elements changed their cluster assignment.\n",
      "2\n",
      "     5126 elements changed their cluster assignment.\n",
      "3\n",
      "     3151 elements changed their cluster assignment.\n",
      "4\n",
      "     2271 elements changed their cluster assignment.\n",
      "5\n",
      "     1763 elements changed their cluster assignment.\n",
      "6\n",
      "     1583 elements changed their cluster assignment.\n",
      "7\n",
      "     1224 elements changed their cluster assignment.\n",
      "8\n",
      "      919 elements changed their cluster assignment.\n",
      "9\n",
      "      686 elements changed their cluster assignment.\n",
      "10\n",
      "      488 elements changed their cluster assignment.\n",
      "11\n",
      "      373 elements changed their cluster assignment.\n",
      "12\n",
      "      250 elements changed their cluster assignment.\n",
      "13\n",
      "      116 elements changed their cluster assignment.\n",
      "14\n",
      "      112 elements changed their cluster assignment.\n",
      "15\n",
      "      133 elements changed their cluster assignment.\n",
      "16\n",
      "      127 elements changed their cluster assignment.\n",
      "17\n",
      "      177 elements changed their cluster assignment.\n",
      "18\n",
      "      169 elements changed their cluster assignment.\n",
      "19\n",
      "      279 elements changed their cluster assignment.\n",
      "20\n",
      "      256 elements changed their cluster assignment.\n",
      "21\n",
      "      188 elements changed their cluster assignment.\n",
      "22\n",
      "      146 elements changed their cluster assignment.\n",
      "23\n",
      "       54 elements changed their cluster assignment.\n",
      "24\n",
      "       72 elements changed their cluster assignment.\n",
      "25\n",
      "       23 elements changed their cluster assignment.\n",
      "26\n",
      "seed=080000, heterogeneity=5494.86183\n",
      "Running k = 50\n",
      "0\n",
      "1\n",
      "    24923 elements changed their cluster assignment.\n",
      "2\n",
      "    12479 elements changed their cluster assignment.\n",
      "3\n",
      "     6070 elements changed their cluster assignment.\n",
      "4\n",
      "     3372 elements changed their cluster assignment.\n",
      "5\n",
      "     1902 elements changed their cluster assignment.\n",
      "6\n",
      "     1461 elements changed their cluster assignment.\n",
      "7\n",
      "     1259 elements changed their cluster assignment.\n",
      "8\n",
      "     1151 elements changed their cluster assignment.\n",
      "9\n",
      "      748 elements changed their cluster assignment.\n",
      "10\n",
      "      424 elements changed their cluster assignment.\n",
      "11\n",
      "      384 elements changed their cluster assignment.\n",
      "12\n",
      "      143 elements changed their cluster assignment.\n",
      "13\n",
      "      213 elements changed their cluster assignment.\n",
      "14\n",
      "       14 elements changed their cluster assignment.\n",
      "15\n",
      "        2 elements changed their cluster assignment.\n",
      "16\n",
      "       39 elements changed their cluster assignment.\n",
      "17\n",
      "seed=020000, heterogeneity=5428.47661\n",
      "0\n",
      "1\n",
      "    24303 elements changed their cluster assignment.\n",
      "2\n",
      "    12036 elements changed their cluster assignment.\n",
      "3\n",
      "     8826 elements changed their cluster assignment.\n",
      "4\n",
      "     6375 elements changed their cluster assignment.\n",
      "5\n",
      "     3190 elements changed their cluster assignment.\n",
      "6\n",
      "     2544 elements changed their cluster assignment.\n",
      "7\n",
      "     1437 elements changed their cluster assignment.\n",
      "8\n",
      "      804 elements changed their cluster assignment.\n",
      "9\n",
      "      454 elements changed their cluster assignment.\n",
      "10\n",
      "      135 elements changed their cluster assignment.\n",
      "11\n",
      "      204 elements changed their cluster assignment.\n",
      "12\n",
      "      158 elements changed their cluster assignment.\n",
      "13\n",
      "      122 elements changed their cluster assignment.\n",
      "14\n",
      "      112 elements changed their cluster assignment.\n",
      "15\n",
      "       38 elements changed their cluster assignment.\n",
      "16\n",
      "       78 elements changed their cluster assignment.\n",
      "17\n",
      "       26 elements changed their cluster assignment.\n",
      "18\n",
      "seed=040000, heterogeneity=5416.88869\n",
      "0\n",
      "1\n",
      "    22146 elements changed their cluster assignment.\n",
      "2\n",
      "    10776 elements changed their cluster assignment.\n",
      "3\n",
      "     6697 elements changed their cluster assignment.\n",
      "4\n",
      "     4947 elements changed their cluster assignment.\n",
      "5\n",
      "     3176 elements changed their cluster assignment.\n",
      "6\n",
      "     1764 elements changed their cluster assignment.\n",
      "7\n",
      "     1195 elements changed their cluster assignment.\n",
      "8\n",
      "      875 elements changed their cluster assignment.\n",
      "9\n",
      "      731 elements changed their cluster assignment.\n",
      "10\n",
      "      427 elements changed their cluster assignment.\n",
      "11\n",
      "      218 elements changed their cluster assignment.\n",
      "12\n",
      "      222 elements changed their cluster assignment.\n",
      "13\n",
      "      271 elements changed their cluster assignment.\n",
      "14\n",
      "      104 elements changed their cluster assignment.\n",
      "15\n",
      "       92 elements changed their cluster assignment.\n",
      "16\n",
      "      132 elements changed their cluster assignment.\n",
      "17\n",
      "       73 elements changed their cluster assignment.\n",
      "18\n",
      "       23 elements changed their cluster assignment.\n",
      "19\n",
      "        1 elements changed their cluster assignment.\n",
      "20\n",
      "seed=080000, heterogeneity=5409.26852\n",
      "Running k = 100\n",
      "0\n",
      "1\n",
      "    31584 elements changed their cluster assignment.\n",
      "2\n",
      "    15286 elements changed their cluster assignment.\n",
      "3\n",
      "     8675 elements changed their cluster assignment.\n",
      "4\n",
      "     5409 elements changed their cluster assignment.\n",
      "5\n",
      "     1936 elements changed their cluster assignment.\n",
      "6\n",
      "      680 elements changed their cluster assignment.\n",
      "7\n",
      "      245 elements changed their cluster assignment.\n",
      "8\n",
      "      124 elements changed their cluster assignment.\n",
      "9\n",
      "       30 elements changed their cluster assignment.\n",
      "10\n",
      "seed=020000, heterogeneity=5313.90735\n",
      "0\n",
      "1\n",
      "    34448 elements changed their cluster assignment.\n",
      "2\n",
      "    15116 elements changed their cluster assignment.\n",
      "3\n",
      "    10060 elements changed their cluster assignment.\n",
      "4\n",
      "     5928 elements changed their cluster assignment.\n",
      "5\n",
      "     3342 elements changed their cluster assignment.\n",
      "6\n",
      "     2004 elements changed their cluster assignment.\n",
      "7\n",
      "     1200 elements changed their cluster assignment.\n",
      "8\n",
      "      751 elements changed their cluster assignment.\n",
      "9\n",
      "      636 elements changed their cluster assignment.\n",
      "10\n",
      "      485 elements changed their cluster assignment.\n",
      "11\n",
      "      269 elements changed their cluster assignment.\n",
      "12\n",
      "      192 elements changed their cluster assignment.\n",
      "13\n",
      "      100 elements changed their cluster assignment.\n",
      "14\n",
      "       57 elements changed their cluster assignment.\n",
      "15\n",
      "       83 elements changed their cluster assignment.\n",
      "16\n",
      "       21 elements changed their cluster assignment.\n",
      "17\n",
      "       80 elements changed their cluster assignment.\n",
      "18\n",
      "seed=040000, heterogeneity=5318.71464\n",
      "0\n",
      "1\n",
      "    37463 elements changed their cluster assignment.\n",
      "2\n",
      "    18569 elements changed their cluster assignment.\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     8610 elements changed their cluster assignment.\n",
      "4\n",
      "     3815 elements changed their cluster assignment.\n",
      "5\n",
      "     2536 elements changed their cluster assignment.\n",
      "6\n",
      "     2023 elements changed their cluster assignment.\n",
      "7\n",
      "     1689 elements changed their cluster assignment.\n",
      "8\n",
      "     1225 elements changed their cluster assignment.\n",
      "9\n",
      "     1016 elements changed their cluster assignment.\n",
      "10\n",
      "     1342 elements changed their cluster assignment.\n",
      "11\n",
      "      582 elements changed their cluster assignment.\n",
      "12\n",
      "      966 elements changed their cluster assignment.\n",
      "13\n",
      "      871 elements changed their cluster assignment.\n",
      "14\n",
      "      941 elements changed their cluster assignment.\n",
      "15\n",
      "      692 elements changed their cluster assignment.\n",
      "16\n",
      "      283 elements changed their cluster assignment.\n",
      "17\n",
      "      303 elements changed their cluster assignment.\n",
      "18\n",
      "      249 elements changed their cluster assignment.\n",
      "19\n",
      "       11 elements changed their cluster assignment.\n",
      "20\n",
      "       50 elements changed their cluster assignment.\n",
      "21\n",
      "       60 elements changed their cluster assignment.\n",
      "22\n",
      "       43 elements changed their cluster assignment.\n",
      "23\n",
      "       64 elements changed their cluster assignment.\n",
      "24\n",
      "       37 elements changed their cluster assignment.\n",
      "25\n",
      "        4 elements changed their cluster assignment.\n",
      "26\n",
      "       16 elements changed their cluster assignment.\n",
      "27\n",
      "seed=080000, heterogeneity=5328.88355\n",
      "CPU times: user 31.9 s, sys: 2.69 s, total: 34.6 s\n",
      "Wall time: 34.5 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def plot_k_vs_heterogeneity(k_values, heterogeneity_values):\n",
    "    \"\"\"\n",
    "    Given list of k-values and their heterogeneities, will make a plot\n",
    "    showing how heterogeneity varies with k.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(k_values, heterogeneity_values, linewidth=4)\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('K vs. Heterogeneity')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()\n",
    "\n",
    "all_centroids = {}\n",
    "all_cluster_assignment = {}\n",
    "heterogeneity_values = []\n",
    "seeds = [20000, 40000, 80000]\n",
    "k_list = [2, 10, 25, 50, 100]\n",
    "\n",
    "for k in k_list:\n",
    "    print(f'Running k = {k}')\n",
    "    heterogeneity = []\n",
    "    all_centroids[k], all_cluster_assignment[k] = kmeans_multiple_runs(tf_idf, k, max_iter=400,\n",
    "                                                                       seeds=seeds, verbose=True)\n",
    "    score = compute_heterogeneity(tf_idf, k, all_centroids[k], all_cluster_assignment[k])\n",
    "    heterogeneity_values.append(score)\n",
    "\n",
    "plot_k_vs_heterogeneity(k_list, heterogeneity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeTT70ORo2hA"
   },
   "source": [
    "# Inspecting clusters of documents\n",
    "Let's start visualizing some clustering results to see if we think the clustering makes sense.  We can use such visualizations to help us assess whether we have set K too large or too small for a given application.  Following the theme of this course, we will judge whether the clustering makes sense in the context of document analysis.\n",
    "\n",
    "What are we looking for in a good clustering of documents?\n",
    "* Documents in the same cluster should be similar.\n",
    "* Documents from different clusters should be less similar.\n",
    "\n",
    "So a bad clustering exhibits either of two symptoms:\n",
    "* Documents in a cluster have mixed content.\n",
    "* Documents with similar content are divided up and put into different clusters.\n",
    "\n",
    "To help visualize the clustering, we do the following:\n",
    "* Fetch nearest neighbors of each centroid from the set of documents assigned to that cluster. We will consider these documents as being representative of the cluster.\n",
    "* Print titles and first sentences of those nearest neighbors.\n",
    "* Print top 5 words that have highest tf-idf weights in each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "8mu1z8g_o2hB"
   },
   "outputs": [],
   "source": [
    "def visualize_document_clusters(wiki, tf_idf, centroids, cluster_assignment, k, words, \n",
    "                                display_docs=5):\n",
    "    \"\"\"\n",
    "    Given a set of clustered documents, prints information about the centroids including\n",
    "       - The title and starting sentence of the closest 5 points to each centroid\n",
    "       - The five words that are contained in the clusters documents with the highest TF-IDF.\n",
    "    \n",
    "    Parameters:  \n",
    "      - wiki: original dataframe\n",
    "      - tf_idf: data matrix containing TF-IDF vectors for each document\n",
    "      - centroids: A np.array of length k that contains the centroids for the clustering\n",
    "      - cluster_assignments: A np.array of length N that has the cluster assignments for each row\n",
    "      - k: What value of k is used\n",
    "      - words: List of words in the corpus (should match tf_idf)\n",
    "      - display_odcs: How many documents to show for each cluster (default 5)\n",
    "    \"\"\"\n",
    "    print('=' * 90)\n",
    "\n",
    "    # Visualize each cluster c\n",
    "    for c in range(k):\n",
    "        # Cluster heading\n",
    "        print(f'Cluster {c}  ({(cluster_assignment == c).sum()} docs)'),\n",
    "        # Print top 5 words with largest TF-IDF weights in the cluster\n",
    "        idx = centroids[c].argsort()[::-1]\n",
    "        for i in range(5): # Print each word along with the TF-IDF weight\n",
    "            print(f'{words[idx[i]]}:{centroids[c,idx[i]]:.3f}', end=' '),\n",
    "        print()\n",
    "        \n",
    "        if display_docs > 0:\n",
    "            print()\n",
    "            # Compute distances from the centroid to all data points in the cluster,\n",
    "            # and compute nearest neighbors of the centroids within the cluster.\n",
    "            distances = pairwise_distances(tf_idf, centroids[c].reshape(1, -1), metric='euclidean').flatten()\n",
    "            distances[cluster_assignment!=c] = float('inf') # remove non-members from consideration\n",
    "            nearest_neighbors = distances.argsort()\n",
    "            # For the nearest neighbors, print the title as well as first 180 characters of text.\n",
    "            # Wrap the text at 80-character mark.\n",
    "            for i in range(display_docs):\n",
    "                text = ' '.join(wiki.iloc[nearest_neighbors[i]]['text'].split(None, 25)[0:25])\n",
    "                print(f'* {wiki.iloc[nearest_neighbors[i]][\"name\"]:50s} {distances[nearest_neighbors[i]]:.5f}')\n",
    "                print(f'  {text[:90]}')\n",
    "                if len(text) > 90:\n",
    "                    print(f'  {text[90:180]}')\n",
    "                print()\n",
    "        print('=' * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfTeu1QLo2hI"
   },
   "source": [
    "Let us first look at the 2 cluster case (K=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "GYmvP9-zo2hJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Cluster 0  (4852 docs)\n",
      "he:0.075 his:0.042 was:0.040 for:0.038 as:0.033 \n",
      "\n",
      "* Wilson McLean                                      0.94057\n",
      "  wilson mclean born 1937 is a scottish illustrator and artist he has illustrated primarily \n",
      "  in the field of advertising but has also provided cover art\n",
      "\n",
      "* Vipin Sharma                                       0.94801\n",
      "  vipin sharma is an indian actor born in new delhi he is a graduate of national school of d\n",
      "  rama new delhi india and the canadian\n",
      "\n",
      "* Nicky Banger                                       0.95174\n",
      "  nicholas lee banger born 25 february 1971 is a retired english professional footballer he \n",
      "  is currently head of commercial operations with woking fcbanger was born\n",
      "\n",
      "* Billy Bingham                                      0.95206\n",
      "  william laurence billy bingham mbe born 5 august 1931 is a former international footballer\n",
      "   and football manager who now works as a scout for english\n",
      "\n",
      "* Wally Whitehurst                                   0.95285\n",
      "  walter richard whitehurst born april 11 1964 in shreveport louisiana is a former righthand\n",
      "  ed pitcher in major league baseball who played from 1989 to 1996\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 1  (1055 docs)\n",
      "she:0.169 her:0.117 was:0.040 for:0.038 as:0.033 \n",
      "\n",
      "* Bhama Srinivasan                                   0.89235\n",
      "  bhama srinivasan april 22 1935 is a mathematician known for her work in the representation\n",
      "   theory of finite groups her contributions were honored with the\n",
      "\n",
      "* Delores Brumfield                                  0.89849\n",
      "  delores brumfield white born may 26 1932 is a former utility infielderoutfielder who playe\n",
      "  d from 1947 through 1953 in the allamerican girls professional baseball league\n",
      "\n",
      "* Natashia Williams                                  0.90086\n",
      "  natashia williamsblach born august 2 1978 is an american actress and former wonderbra camp\n",
      "  aign model who is perhaps best known for her role as shane\n",
      "\n",
      "* Gila Golan                                         0.90518\n",
      "  gila golan hebrew born 1940 is a polishborn israeli former fashion model and actressgolan \n",
      "  was born in krakw poland around 1940 her exact birthday is\n",
      "\n",
      "* Bette McLaurin                                     0.90751\n",
      "  bette mclaurin born c1929 is an africanamerican singer best known for her jazzinfluenced b\n",
      "  allad and rb performances in the 1950s two of her recordings i\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "visualize_document_clusters(wiki, tf_idf, all_centroids[k], all_cluster_assignment[k], k, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRxFMTbCo2hJ"
   },
   "source": [
    "Both clusters have mixed content, although clearly cluster 0 are all women and cluster 1 are all men:\n",
    "\n",
    "It would be better if we sub-divided into more categories. So let us use more clusters. How about `K=10`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "6wyouWqqo2hJ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Cluster 0  (619 docs)\n",
      "he:0.078 university:0.071 research:0.053 at:0.048 professor:0.042 \n",
      "\n",
      "* Elijah Anderson                                    0.92453\n",
      "  elijah anderson is an american sociologist he holds the william k lanman jr professorship \n",
      "  in sociology at yale university where he teaches and directs the\n",
      "\n",
      "* Sal Restivo                                        0.92760\n",
      "  sal restivo born 1940 is a sociologistanthropologist he is a leading contributor to scienc\n",
      "  e studies and in particular to the sociology of mathematical knowledge his\n",
      "\n",
      "* Daniel Berg (educator)                             0.93122\n",
      "  daniel berg is a scientist educator and was the fifteenth president of rensselaer polytech\n",
      "  nic institutehe was born on june 1 1929 in new york city\n",
      "\n",
      "* Stuart Henry (criminologist)                       0.93151\n",
      "  stuart henry is professor of criminal justice and director of the school of public affairs\n",
      "   san diego state university 2006 he has also been appointed\n",
      "\n",
      "* Robert Pollack (biologist)                         0.93384\n",
      "  dr robert pollack is an american biologist who studies the intersections between science a\n",
      "  nd religion he currently works at columbia university where he serves as\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 1  (361 docs)\n",
      "he:0.075 coach:0.052 team:0.048 at:0.046 world:0.041 \n",
      "\n",
      "* Christopher Hedquist                               0.93353\n",
      "  christopher hedquist born june 4 1980 salt lake city utah is an american skeleton racer in\n",
      "   2004 he won the overall european cup becoming the\n",
      "\n",
      "* Mike Houston (American football)                   0.93621\n",
      "  mike houston born c 1971 is an american college football coach currently serving as head c\n",
      "  oach of the citadel bulldogs football team he was named\n",
      "\n",
      "* Marty Krulee                                       0.93705\n",
      "  marty krulee born november 4 1956 is an american world class track and field athlete prima\n",
      "  rily known for running sprint races while never achieving outstanding\n",
      "\n",
      "* Yordanis Garc%C3%ADa                               0.93997\n",
      "  yordanis garca barrisonte spanish pronunciation oranis arsia arisonte born november 21 198\n",
      "  8 in san juan y martnez pinar del ro is a male decathlete from\n",
      "\n",
      "* Otis Harris                                        0.94147\n",
      "  for the singer see damon harrisotis harris born june 30 1982 in edwards mississippi is an \n",
      "  american track field athlete he won the silver medal\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 2  (1346 docs)\n",
      "he:0.061 his:0.041 was:0.037 for:0.036 as:0.031 \n",
      "\n",
      "* Sandro Petrone                                     0.95231\n",
      "  sandro petrone is a foreign war correspondent and anchorman for rai italian state radio an\n",
      "  d television currently working as editor for foreign news for tg2\n",
      "\n",
      "* Bali Rai                                           0.95800\n",
      "  bali rai was born in leicester in 1971 and grew up in a multicultural multiracial communit\n",
      "  y close to the city centre as a child he\n",
      "\n",
      "* Josh Lukevich                                      0.96090\n",
      "  josh lukevich was born on november 9 1976 in seattle washington at the age of 6 he spent a\n",
      "   year traveling across the united statesin\n",
      "\n",
      "* David Benkof                                       0.96207\n",
      "  david benkof born david bianco in 1970 is an american political commentator and entreprene\n",
      "  ur he was raised in st louis missouri and then went to\n",
      "\n",
      "* Mark Law                                           0.96224\n",
      "  mark alexander law born november 1944 is a british journalist and author he lives in londo\n",
      "  nmark law is a former fleet street journalist he is\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 3  (327 docs)\n",
      "film:0.121 he:0.060 for:0.045 television:0.042 films:0.041 \n",
      "\n",
      "* Robert Braiden                                     0.90548\n",
      "  robert braiden is an australian film director and writer born in sydney he grew up in moor\n",
      "  ebank liverpool new south wales and now currently lives\n",
      "\n",
      "* Paul Swadel                                        0.90981\n",
      "  paul swadel is a new zealand film director and producerhe has directed and produced many s\n",
      "  uccessful short films which have screened in competition at cannes\n",
      "\n",
      "* Bruce Redman                                       0.91495\n",
      "  dr bruce redman born 25 april 1960 is an australian film director film critic radio person\n",
      "  ality and media relations manager he currently works for the\n",
      "\n",
      "* Hossein Shahabi                                    0.91619\n",
      "  hossein shahabi persian is an iranian film director screenwriter and film producer he belo\n",
      "  ngs is to the third generation of iranian new wave who was\n",
      "\n",
      "* Matthew Saville                                    0.91760\n",
      "  matthew saville is an australian television and film director who began his career working\n",
      "   as a titles designer for many australian television series several of\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 4  (690 docs)\n",
      "music:0.072 he:0.059 album:0.048 with:0.047 band:0.046 \n",
      "\n",
      "* Graham Ord                                         0.93042\n",
      "  graham ord born 22 march 1961 is an english musician and songwriter he has garnered respec\n",
      "  t internationally as a fine musician and engaging communicator his\n",
      "\n",
      "* David Oei                                          0.93451\n",
      "  david oei chinese name pinyin hung jln surname pronounced wee is hong kongborn american cl\n",
      "  assical pianist b 1950 in hong kongoei was born in hong\n",
      "\n",
      "* Richard Warren (musician)                          0.93576\n",
      "  richard daniel warren born 3 june 1973 is a british musician songwriter and producerhe sig\n",
      "  ned his first record deal with heavenly records at the height\n",
      "\n",
      "* Martin Russell                                     0.93809\n",
      "  martin russell is a recording engineer producer composer and musician he has been a core m\n",
      "  ember of the music group afro celt sound system since\n",
      "\n",
      "* Mark Wilkinson (singer)                            0.93898\n",
      "  mark wilkinson singer born buckinghamshire england is an australian country singersongwrit\n",
      "  er whose lyrical depth gift for melody and impassioned delivery are quickly establishing h\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 5  (182 docs)\n",
      "art:0.159 museum:0.075 gallery:0.052 he:0.048 his:0.045 \n",
      "\n",
      "* Tom Moody (artist)                                 0.87712\n",
      "  tom moody is a visual artist critic and blogger based in new york city he began his career\n",
      "   as a painter using traditional materials but\n",
      "\n",
      "* Michael Hafftka                                    0.87740\n",
      "  michael hafftka is an american figurative expressionist painter living in new york city hi\n",
      "  s work is represented in the permanent collections of a number of\n",
      "\n",
      "* Burton Silverman                                   0.88510\n",
      "  burton silverman born 1928 is an american paintera 1949 graduate of columbia university si\n",
      "  lvermans work has concentrated on as he put it the landscape of\n",
      "\n",
      "* Charles Arnoldi                                    0.88747\n",
      "  charles arnoldi also known as chuck arnoldi and as charles arthur arnoldi is an american p\n",
      "  ainter sculptor and printmaker he was born april 10 1946\n",
      "\n",
      "* Steven Montgomery                                  0.89140\n",
      "  steven montgomery is an american artist born in detroit 1954 most often associated with la\n",
      "  rge scale ceramic sculpture suggesting industrial objects or mechanical detritus he\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 6  (763 docs)\n",
      "he:0.082 was:0.058 as:0.045 for:0.038 from:0.036 \n",
      "\n",
      "* Doug Naysmith                                      0.93318\n",
      "  john douglas naysmith born 1 april 1941 is a british labour cooperative politician who was\n",
      "   the member of parliament mp for bristol north west from\n",
      "\n",
      "* John Garamendi                                     0.93705\n",
      "  john raymond garamendi born january 24 1945 is an american rancher businessman politician \n",
      "  and member of the democratic party who has represented areas of northern\n",
      "\n",
      "* Bill Clinton                                       0.93786\n",
      "  william jefferson bill clinton born william jefferson blythe iii august 19 1946 is an amer\n",
      "  ican politician who served from 1993 to 2001 as the 42nd\n",
      "\n",
      "* Jim Elder (politician)                             0.94113\n",
      "  james peter jim elder born 14 december 1950 is a former australian politician he was a mem\n",
      "  ber of the legislative assembly of queensland from 1989\n",
      "\n",
      "* Levin H. Campbell                                  0.94264\n",
      "  levin hicks campbell born january 2 1927 is an american federal appellate judge on senior \n",
      "  status with the united states court of appeals for the\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 7  (173 docs)\n",
      "league:0.137 baseball:0.123 he:0.096 major:0.070 games:0.063 \n",
      "\n",
      "* Alfonso Pulido                                     0.85985\n",
      "  alfonso pulido manzo born january 23 1957 in tierra blanca veracruz is a former major leag\n",
      "  ue baseball pitcher pulido played parts of three seasons in\n",
      "\n",
      "* Joe Strong                                         0.86372\n",
      "  joseph benjamin strong born september 9 1962 in fairfield california is a former major lea\n",
      "  gue baseball pitcher who played for the florida marlins from 2000\n",
      "\n",
      "* Dom Zanni                                          0.86748\n",
      "  dominick thomas zanni born march 1 1932 in the bronx new york is a former professional bas\n",
      "  eball player a righthanded pitcher he pitched in 111\n",
      "\n",
      "* Clyde Mashore                                      0.86834\n",
      "  clyde wayne mashore born may 29 1945 in concord california is a former major league baseba\n",
      "  ll outfielder who played in 241 games over five seasons\n",
      "\n",
      "* Wally Whitehurst                                   0.87336\n",
      "  walter richard whitehurst born april 11 1964 in shreveport louisiana is a former righthand\n",
      "  ed pitcher in major league baseball who played from 1989 to 1996\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 8  (602 docs)\n",
      "he:0.096 football:0.063 season:0.059 played:0.057 his:0.056 \n",
      "\n",
      "* Tony Smith (footballer, born 1957)                 0.90547\n",
      "  anthony tony smith born 20 february 1957 is a former footballer who played as a central de\n",
      "  fender in the football league in the 1970s and\n",
      "\n",
      "* Steve Bruce                                        0.91523\n",
      "  stephen roger steve bruce born 31 december 1960 is an english football manager and former \n",
      "  player who is currently the manager at hull city born\n",
      "\n",
      "* Shane Hobbs                                        0.91816\n",
      "  shane hobbs born 30 april 1985 is a former professional footballer who played in the footb\n",
      "  all league for bristol rovers in 2003 and currently plays\n",
      "\n",
      "* Roy Keane                                          0.91848\n",
      "  royston maurice roy keane born 10 august 1971 is an irish football manager and former prof\n",
      "  essional football player he is the assistant manager of the\n",
      "\n",
      "* Billy Bingham                                      0.91848\n",
      "  william laurence billy bingham mbe born 5 august 1931 is a former international footballer\n",
      "   and football manager who now works as a scout for english\n",
      "\n",
      "==========================================================================================\n",
      "Cluster 9  (844 docs)\n",
      "she:0.185 her:0.129 was:0.042 for:0.039 as:0.033 \n",
      "\n",
      "* Bhama Srinivasan                                   0.88691\n",
      "  bhama srinivasan april 22 1935 is a mathematician known for her work in the representation\n",
      "   theory of finite groups her contributions were honored with the\n",
      "\n",
      "* Delores Brumfield                                  0.89357\n",
      "  delores brumfield white born may 26 1932 is a former utility infielderoutfielder who playe\n",
      "  d from 1947 through 1953 in the allamerican girls professional baseball league\n",
      "\n",
      "* Natashia Williams                                  0.89674\n",
      "  natashia williamsblach born august 2 1978 is an american actress and former wonderbra camp\n",
      "  aign model who is perhaps best known for her role as shane\n",
      "\n",
      "* Gila Golan                                         0.89928\n",
      "  gila golan hebrew born 1940 is a polishborn israeli former fashion model and actressgolan \n",
      "  was born in krakw poland around 1940 her exact birthday is\n",
      "\n",
      "* Bette McLaurin                                     0.90251\n",
      "  bette mclaurin born c1929 is an africanamerican singer best known for her jazzinfluenced b\n",
      "  allad and rb performances in the 1950s two of her recordings i\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "visualize_document_clusters(wiki, tf_idf, all_centroids[k], all_cluster_assignment[k], k, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM0WgtALo2hJ"
   },
   "source": [
    "We no longer have the clear split between men and women. Cluters 0 and 2 appear to be still mixed, but others are quite consistent in content.\n",
    "* Cluster 0: notable women\n",
    "* Cluster 1: baseball players\n",
    "* Cluster 2: researchers, professors\n",
    "* Cluster 3: football(soccer)\n",
    "* Cluster 4: musicians, singers, song writers\n",
    "* Cluster 5: golfers\n",
    "* Cluster 6: painters, scultpers, artists\n",
    "* Cluster 7: orchestral musicians, conductors\n",
    "* Cluster 8: politicians, political personel\n",
    "* Cluster 9: film directors|\n",
    "\n",
    "Clusters are now more pure, but some are qualitatively \"bigger\" than others. For instance, the category of scholars is more general than the category of film directors. Increasing the number of clusters may split larger clusters. Another way to look at the size of cluster is to count the number of articles in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "usdE_dY-o2hJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 619,  361, 1346,  327,  690,  182,  763,  173,  602,  844])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(all_cluster_assignment[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtcTBHm0o2hJ"
   },
   "source": [
    "There appears to be at least some connection between the topical consistency of a cluster and the number of its member data points.\n",
    "\n",
    "Let us visualize the case for K=25. For the sake of brevity, we do not print the content of documents. It turns out that the top words with highest TF-IDF weights in each cluster are representative of the cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "WK0kifvoo2hJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Cluster 0  (476 docs)\n",
      "she:0.215 her:0.096 was:0.046 for:0.038 as:0.034 \n",
      "==========================================================================================\n",
      "Cluster 1  (144 docs)\n",
      "film:0.212 films:0.060 he:0.055 festival:0.050 for:0.045 \n",
      "==========================================================================================\n",
      "Cluster 2  (37 docs)\n",
      "taylor:0.083 he:0.049 was:0.042 his:0.040 for:0.037 \n",
      "==========================================================================================\n",
      "Cluster 3  (92 docs)\n",
      "law:0.185 court:0.092 he:0.077 judge:0.070 district:0.052 \n",
      "==========================================================================================\n",
      "Cluster 4  (28 docs)\n",
      "animation:0.130 animated:0.068 he:0.061 animator:0.055 film:0.054 \n",
      "==========================================================================================\n",
      "Cluster 5  (167 docs)\n",
      "league:0.138 baseball:0.121 he:0.098 major:0.072 games:0.065 \n",
      "==========================================================================================\n",
      "Cluster 6  (505 docs)\n",
      "he:0.090 was:0.060 as:0.048 election:0.043 party:0.042 \n",
      "==========================================================================================\n",
      "Cluster 7  (146 docs)\n",
      "tour:0.112 orchestra:0.105 he:0.087 pga:0.078 music:0.062 \n",
      "==========================================================================================\n",
      "Cluster 8  (96 docs)\n",
      "racing:0.109 he:0.080 championship:0.071 race:0.062 car:0.054 \n",
      "==========================================================================================\n",
      "Cluster 9  (483 docs)\n",
      "he:0.076 university:0.072 research:0.059 at:0.048 professor:0.042 \n",
      "==========================================================================================\n",
      "Cluster 10  (258 docs)\n",
      "published:0.057 book:0.053 he:0.050 novel:0.043 poetry:0.042 \n",
      "==========================================================================================\n",
      "Cluster 11  (65 docs)\n",
      "economics:0.155 economic:0.094 he:0.088 university:0.077 professor:0.049 \n",
      "==========================================================================================\n",
      "Cluster 12  (254 docs)\n",
      "was:0.059 he:0.055 that:0.044 his:0.038 for:0.033 \n",
      "==========================================================================================\n",
      "Cluster 13  (364 docs)\n",
      "her:0.166 she:0.142 for:0.040 was:0.036 as:0.035 \n",
      "==========================================================================================\n",
      "Cluster 14  (66 docs)\n",
      "australian:0.136 australia:0.085 he:0.066 sydney:0.056 was:0.047 \n",
      "==========================================================================================\n",
      "Cluster 15  (137 docs)\n",
      "championships:0.096 he:0.067 world:0.066 at:0.061 olympics:0.058 \n",
      "==========================================================================================\n",
      "Cluster 16  (80 docs)\n",
      "coach:0.238 head:0.093 he:0.072 football:0.066 basketball:0.062 \n",
      "==========================================================================================\n",
      "Cluster 17  (501 docs)\n",
      "he:0.095 football:0.069 league:0.058 season:0.058 played:0.057 \n",
      "==========================================================================================\n",
      "Cluster 18  (444 docs)\n",
      "he:0.074 music:0.055 his:0.047 as:0.042 for:0.042 \n",
      "==========================================================================================\n",
      "Cluster 19  (862 docs)\n",
      "he:0.062 his:0.037 for:0.034 was:0.033 as:0.032 \n",
      "==========================================================================================\n",
      "Cluster 20  (57 docs)\n",
      "bishop:0.135 church:0.095 he:0.094 theology:0.084 catholic:0.059 \n",
      "==========================================================================================\n",
      "Cluster 21  (166 docs)\n",
      "art:0.165 museum:0.079 gallery:0.057 he:0.048 work:0.046 \n",
      "==========================================================================================\n",
      "Cluster 22  (344 docs)\n",
      "album:0.085 band:0.077 he:0.050 with:0.047 released:0.047 \n",
      "==========================================================================================\n",
      "Cluster 23  (72 docs)\n",
      "radio:0.175 show:0.086 he:0.077 on:0.059 for:0.048 \n",
      "==========================================================================================\n",
      "Cluster 24  (63 docs)\n",
      "hockey:0.242 nhl:0.109 season:0.079 ice:0.077 he:0.075 \n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 25\n",
    "visualize_document_clusters(wiki, tf_idf, all_centroids[k], all_cluster_assignment[k], k,\n",
    "                            words, display_docs=0) # turn off text for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gci3rw-Io2hK"
   },
   "source": [
    "Looking at the representative examples and top words, we classify each cluster as follows. Notice the bolded items, which indicate the appearance of a new theme.\n",
    "* Cluster 0: **British labor party**\n",
    "* Cluster 1: **Bishops**\n",
    "* Cluster 2: **danish CEOs**\n",
    "* Cluster 3: baseball\n",
    "* Cluster 4: politicials\n",
    "* Cluster 5: **psychology researchers**\n",
    "* Cluster 6: **medical researchers**\n",
    "* Cluster 7: **republican politicians**\n",
    "* Cluster 8: football(soccer)\n",
    "* Cluster 9: **prime ministers**\n",
    "* Cluster 10: golfers\n",
    "* Cluster 11: coaches\n",
    "* Cluster 12: **lawers**\n",
    "* Cluster 13: researchers, professors\n",
    "* Cluster 14: writers\n",
    "* Cluster 15: artists, museaum workers\n",
    "* Cluster 16: film directors\n",
    "* Cluster 17: musicians\n",
    "* Cluster 18: **airforce commanders**\n",
    "* Cluster 19: orchestral musicians\n",
    "* Cluster 20: *unclear*\n",
    "* Cluster 21: *unclear*\n",
    "* Cluster 22: *unclear*\n",
    "* Cluster 23: politicians\n",
    "* Cluster 24: **hockey players**\n",
    "\n",
    "Indeed, increasing K achieved the desired effect of breaking up large clusters.  Depending on the application, this may or may not be preferable to the K=10 analysis.\n",
    "\n",
    "Let's take it to the extreme and set K=100. We have a suspicion that this value is too large. Let us look at the top words from each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "8JRj1ck1o2hK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Cluster 0  (2 docs)\n",
      "stearns:0.318 hombs:0.222 homelessness:0.137 yoho:0.133 washington:0.122 \n",
      "==========================================================================================\n",
      "Cluster 1  (18 docs)\n",
      "jersey:0.210 new:0.091 assembly:0.064 state:0.058 he:0.058 \n",
      "==========================================================================================\n",
      "Cluster 2  (38 docs)\n",
      "law:0.303 legal:0.089 he:0.074 school:0.054 university:0.050 \n",
      "==========================================================================================\n",
      "Cluster 3  (10 docs)\n",
      "comedy:0.254 standup:0.172 show:0.107 comedian:0.089 orben:0.069 \n",
      "==========================================================================================\n",
      "Cluster 4  (56 docs)\n",
      "hockey:0.253 nhl:0.117 season:0.086 ice:0.086 he:0.076 \n",
      "==========================================================================================\n",
      "Cluster 5  (38 docs)\n",
      "bbc:0.192 television:0.066 he:0.063 for:0.062 radio:0.055 \n",
      "==========================================================================================\n",
      "Cluster 6  (45 docs)\n",
      "she:0.262 her:0.127 baseball:0.063 was:0.051 girls:0.041 \n",
      "==========================================================================================\n",
      "Cluster 7  (118 docs)\n",
      "he:0.072 university:0.062 research:0.050 at:0.041 society:0.037 \n",
      "==========================================================================================\n",
      "Cluster 8  (32 docs)\n",
      "theatre:0.268 play:0.057 directed:0.056 at:0.055 plays:0.047 \n",
      "==========================================================================================\n",
      "Cluster 9  (8 docs)\n",
      "war:0.117 communist:0.073 yugoslavia:0.068 victims:0.065 his:0.063 \n",
      "==========================================================================================\n",
      "Cluster 10  (121 docs)\n",
      "art:0.190 museum:0.100 gallery:0.070 he:0.053 his:0.049 \n",
      "==========================================================================================\n",
      "Cluster 11  (37 docs)\n",
      "opera:0.317 she:0.073 at:0.048 with:0.046 he:0.043 \n",
      "==========================================================================================\n",
      "Cluster 12  (9 docs)\n",
      "croatian:0.133 he:0.082 formula:0.073 todori:0.070 enduro:0.067 \n",
      "==========================================================================================\n",
      "Cluster 13  (15 docs)\n",
      "wrestling:0.254 wwe:0.126 wrestler:0.090 champion:0.080 championship:0.078 \n",
      "==========================================================================================\n",
      "Cluster 14  (55 docs)\n",
      "research:0.095 he:0.076 university:0.051 medicine:0.049 medical:0.044 \n",
      "==========================================================================================\n",
      "Cluster 15  (42 docs)\n",
      "music:0.102 he:0.067 his:0.058 los:0.045 album:0.042 \n",
      "==========================================================================================\n",
      "Cluster 16  (25 docs)\n",
      "world:0.100 champion:0.082 olympic:0.074 team:0.059 championships:0.058 \n",
      "==========================================================================================\n",
      "Cluster 17  (40 docs)\n",
      "governor:0.181 state:0.074 he:0.064 was:0.061 democratic:0.056 \n",
      "==========================================================================================\n",
      "Cluster 18  (112 docs)\n",
      "novel:0.080 published:0.070 poetry:0.064 her:0.058 she:0.057 \n",
      "==========================================================================================\n",
      "Cluster 19  (34 docs)\n",
      "music:0.057 hop:0.053 hip:0.052 for:0.051 has:0.048 \n",
      "==========================================================================================\n",
      "Cluster 20  (230 docs)\n",
      "her:0.186 she:0.168 was:0.037 for:0.034 with:0.033 \n",
      "==========================================================================================\n",
      "Cluster 21  (73 docs)\n",
      "coach:0.221 football:0.087 head:0.085 he:0.072 coaching:0.057 \n",
      "==========================================================================================\n",
      "Cluster 22  (11 docs)\n",
      "fc:0.104 club:0.100 season:0.100 ligue:0.076 he:0.075 \n",
      "==========================================================================================\n",
      "Cluster 23  (23 docs)\n",
      "art:0.071 video:0.068 she:0.067 for:0.048 design:0.045 \n",
      "==========================================================================================\n",
      "Cluster 24  (3 docs)\n",
      "rugby:0.274 tuilagi:0.204 watkins:0.195 newport:0.175 gwent:0.156 \n",
      "==========================================================================================\n",
      "Cluster 25  (46 docs)\n",
      "league:0.130 runs:0.123 baseball:0.107 he:0.089 batted:0.080 \n",
      "==========================================================================================\n",
      "Cluster 26  (17 docs)\n",
      "rabbi:0.201 jewish:0.156 he:0.071 religion:0.058 religious:0.057 \n",
      "==========================================================================================\n",
      "Cluster 27  (14 docs)\n",
      "he:0.066 his:0.051 has:0.051 sculpture:0.048 tap:0.048 \n",
      "==========================================================================================\n",
      "Cluster 28  (47 docs)\n",
      "computer:0.082 he:0.072 software:0.061 computing:0.049 university:0.048 \n",
      "==========================================================================================\n",
      "Cluster 29  (85 docs)\n",
      "racing:0.097 he:0.079 chess:0.079 championship:0.076 poker:0.055 \n",
      "==========================================================================================\n",
      "Cluster 30  (73 docs)\n",
      "orchestra:0.199 music:0.121 symphony:0.106 philharmonic:0.071 chamber:0.066 \n",
      "==========================================================================================\n",
      "Cluster 31  (241 docs)\n",
      "he:0.087 party:0.067 was:0.064 election:0.063 as:0.044 \n",
      "==========================================================================================\n",
      "Cluster 32  (19 docs)\n",
      "austrian:0.092 police:0.070 mayer:0.062 he:0.060 his:0.050 \n",
      "==========================================================================================\n",
      "Cluster 33  (91 docs)\n",
      "he:0.083 research:0.078 university:0.065 science:0.064 engineering:0.050 \n",
      "==========================================================================================\n",
      "Cluster 34  (17 docs)\n",
      "episode:0.081 jordan:0.063 as:0.043 his:0.042 he:0.042 \n",
      "==========================================================================================\n",
      "Cluster 35  (14 docs)\n",
      "language:0.171 she:0.073 linguistics:0.071 psychology:0.068 university:0.060 \n",
      "==========================================================================================\n",
      "Cluster 36  (27 docs)\n",
      "animation:0.110 film:0.082 animated:0.078 he:0.058 for:0.056 \n",
      "==========================================================================================\n",
      "Cluster 37  (15 docs)\n",
      "gael:0.138 election:0.125 general:0.109 fine:0.107 dublin:0.106 \n",
      "==========================================================================================\n",
      "Cluster 38  (140 docs)\n",
      "he:0.089 film:0.069 actor:0.055 his:0.053 as:0.046 \n",
      "==========================================================================================\n",
      "Cluster 39  (45 docs)\n",
      "air:0.116 command:0.090 commander:0.082 he:0.075 force:0.074 \n",
      "==========================================================================================\n",
      "Cluster 40  (21 docs)\n",
      "miss:0.333 pageant:0.169 she:0.156 usa:0.114 her:0.090 \n",
      "==========================================================================================\n",
      "Cluster 41  (122 docs)\n",
      "league:0.138 baseball:0.125 he:0.102 major:0.077 season:0.070 \n",
      "==========================================================================================\n",
      "Cluster 42  (34 docs)\n",
      "dj:0.122 radio:0.091 show:0.069 he:0.067 his:0.057 \n",
      "==========================================================================================\n",
      "Cluster 43  (64 docs)\n",
      "he:0.069 editor:0.060 book:0.058 for:0.045 published:0.042 \n",
      "==========================================================================================\n",
      "Cluster 44  (50 docs)\n",
      "tour:0.303 pga:0.226 golf:0.128 he:0.112 his:0.079 \n",
      "==========================================================================================\n",
      "Cluster 45  (8 docs)\n",
      "hurling:0.361 cork:0.236 intercounty:0.160 tipperary:0.154 munster:0.139 \n",
      "==========================================================================================\n",
      "Cluster 46  (2 docs)\n",
      "favre:0.235 godard:0.207 valrie:0.165 exh:0.148 france:0.127 \n",
      "==========================================================================================\n",
      "Cluster 47  (46 docs)\n",
      "marathon:0.144 metres:0.138 championships:0.133 she:0.106 athletics:0.086 \n",
      "==========================================================================================\n",
      "Cluster 48  (107 docs)\n",
      "radio:0.088 he:0.066 sports:0.058 for:0.055 on:0.054 \n",
      "==========================================================================================\n",
      "Cluster 49  (19 docs)\n",
      "ocean:0.072 swim:0.064 swimming:0.063 he:0.062 world:0.041 \n",
      "==========================================================================================\n",
      "Cluster 50  (8 docs)\n",
      "russian:0.130 bridgeman:0.086 yerevan:0.084 sargsyan:0.081 1st:0.076 \n",
      "==========================================================================================\n",
      "Cluster 51  (65 docs)\n",
      "olympics:0.083 championships:0.078 team:0.063 at:0.061 he:0.059 \n",
      "==========================================================================================\n",
      "Cluster 52  (148 docs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music:0.125 he:0.075 jazz:0.066 piano:0.052 with:0.051 \n",
      "==========================================================================================\n",
      "Cluster 53  (67 docs)\n",
      "minister:0.198 he:0.090 was:0.064 prime:0.062 as:0.052 \n",
      "==========================================================================================\n",
      "Cluster 54  (4 docs)\n",
      "gyllenhammar:0.151 exhibition:0.148 sweden:0.140 stockholm:0.125 her:0.121 \n",
      "==========================================================================================\n",
      "Cluster 55  (30 docs)\n",
      "photography:0.076 photographer:0.061 he:0.058 fashion:0.054 his:0.051 \n",
      "==========================================================================================\n",
      "Cluster 56  (24 docs)\n",
      "band:0.129 drummer:0.083 rock:0.068 metal:0.058 bands:0.057 \n",
      "==========================================================================================\n",
      "Cluster 57  (36 docs)\n",
      "digital:0.071 entertainment:0.059 media:0.058 he:0.048 executive:0.042 \n",
      "==========================================================================================\n",
      "Cluster 58  (16 docs)\n",
      "water:0.132 he:0.056 polo:0.053 his:0.038 hay:0.035 \n",
      "==========================================================================================\n",
      "Cluster 59  (67 docs)\n",
      "album:0.156 her:0.149 she:0.101 released:0.068 on:0.051 \n",
      "==========================================================================================\n",
      "Cluster 60  (142 docs)\n",
      "he:0.084 court:0.055 was:0.054 law:0.053 from:0.052 \n",
      "==========================================================================================\n",
      "Cluster 61  (42 docs)\n",
      "she:0.161 series:0.108 role:0.069 her:0.065 episode:0.056 \n",
      "==========================================================================================\n",
      "Cluster 62  (104 docs)\n",
      "she:0.165 her:0.150 film:0.066 actress:0.061 for:0.048 \n",
      "==========================================================================================\n",
      "Cluster 63  (13 docs)\n",
      "referee:0.218 fifa:0.106 refereeing:0.080 he:0.080 uefa:0.073 \n",
      "==========================================================================================\n",
      "Cluster 64  (118 docs)\n",
      "band:0.129 guitar:0.074 he:0.061 with:0.052 album:0.051 \n",
      "==========================================================================================\n",
      "Cluster 65  (36 docs)\n",
      "yards:0.178 nfl:0.160 football:0.131 he:0.080 rushing:0.068 \n",
      "==========================================================================================\n",
      "Cluster 66  (37 docs)\n",
      "mathematics:0.121 mathematical:0.103 university:0.101 he:0.080 professor:0.076 \n",
      "==========================================================================================\n",
      "Cluster 67  (31 docs)\n",
      "philosophy:0.200 he:0.063 science:0.059 university:0.058 professor:0.054 \n",
      "==========================================================================================\n",
      "Cluster 68  (526 docs)\n",
      "he:0.061 his:0.041 was:0.038 for:0.030 as:0.029 \n",
      "==========================================================================================\n",
      "Cluster 69  (39 docs)\n",
      "he:0.050 his:0.045 that:0.041 for:0.030 was:0.030 \n",
      "==========================================================================================\n",
      "Cluster 70  (107 docs)\n",
      "he:0.064 design:0.054 new:0.053 york:0.050 architecture:0.038 \n",
      "==========================================================================================\n",
      "Cluster 71  (9 docs)\n",
      "bury:0.120 league:0.115 he:0.101 wigan:0.077 appearances:0.075 \n",
      "==========================================================================================\n",
      "Cluster 72  (48 docs)\n",
      "he:0.086 his:0.061 tennis:0.059 won:0.050 open:0.040 \n",
      "==========================================================================================\n",
      "Cluster 73  (41 docs)\n",
      "de:0.193 he:0.070 la:0.049 his:0.045 was:0.030 \n",
      "==========================================================================================\n",
      "Cluster 74  (20 docs)\n",
      "cricket:0.190 firstclass:0.114 he:0.088 batsman:0.080 played:0.078 \n",
      "==========================================================================================\n",
      "Cluster 75  (66 docs)\n",
      "rugby:0.191 he:0.084 for:0.071 played:0.067 against:0.063 \n",
      "==========================================================================================\n",
      "Cluster 76  (70 docs)\n",
      "church:0.144 bishop:0.119 he:0.094 was:0.062 diocese:0.047 \n",
      "==========================================================================================\n",
      "Cluster 77  (49 docs)\n",
      "for:0.057 she:0.056 on:0.051 news:0.047 as:0.046 \n",
      "==========================================================================================\n",
      "Cluster 78  (16 docs)\n",
      "song:0.129 philippines:0.081 aquino:0.073 manila:0.068 music:0.052 \n",
      "==========================================================================================\n",
      "Cluster 79  (55 docs)\n",
      "he:0.065 was:0.064 his:0.043 on:0.042 court:0.041 \n",
      "==========================================================================================\n",
      "Cluster 80  (26 docs)\n",
      "comics:0.120 comic:0.098 for:0.062 series:0.055 he:0.049 \n",
      "==========================================================================================\n",
      "Cluster 81  (44 docs)\n",
      "he:0.070 was:0.055 that:0.048 military:0.047 egyptian:0.040 \n",
      "==========================================================================================\n",
      "Cluster 82  (65 docs)\n",
      "football:0.134 afl:0.125 australian:0.096 he:0.079 played:0.075 \n",
      "==========================================================================================\n",
      "Cluster 83  (48 docs)\n",
      "health:0.122 medical:0.072 medicine:0.068 research:0.060 he:0.060 \n",
      "==========================================================================================\n",
      "Cluster 84  (97 docs)\n",
      "economics:0.098 university:0.095 he:0.089 economic:0.062 at:0.057 \n",
      "==========================================================================================\n",
      "Cluster 85  (28 docs)\n",
      "poetry:0.064 he:0.056 his:0.050 poems:0.048 poet:0.038 \n",
      "==========================================================================================\n",
      "Cluster 86  (40 docs)\n",
      "chinese:0.110 china:0.087 he:0.062 martial:0.041 his:0.041 \n",
      "==========================================================================================\n",
      "Cluster 87  (38 docs)\n",
      "news:0.141 he:0.088 space:0.064 for:0.056 on:0.050 \n",
      "==========================================================================================\n",
      "Cluster 88  (16 docs)\n",
      "belarusian:0.062 that:0.062 was:0.048 he:0.047 charges:0.044 \n",
      "==========================================================================================\n",
      "Cluster 89  (74 docs)\n",
      "music:0.065 records:0.057 he:0.046 his:0.044 with:0.041 \n",
      "==========================================================================================\n",
      "Cluster 90  (61 docs)\n",
      "basketball:0.174 nba:0.107 points:0.085 he:0.081 player:0.064 \n",
      "==========================================================================================\n",
      "Cluster 91  (134 docs)\n",
      "album:0.101 he:0.062 his:0.056 released:0.054 band:0.050 \n",
      "==========================================================================================\n",
      "Cluster 92  (235 docs)\n",
      "he:0.107 league:0.077 football:0.076 club:0.059 season:0.059 \n",
      "==========================================================================================\n",
      "Cluster 93  (27 docs)\n",
      "she:0.102 minister:0.073 was:0.055 for:0.050 affairs:0.045 \n",
      "==========================================================================================\n",
      "Cluster 94  (27 docs)\n",
      "board:0.109 chairman:0.093 he:0.077 executive:0.055 vodafone:0.053 \n",
      "==========================================================================================\n",
      "Cluster 95  (6 docs)\n",
      "mount:0.137 spine:0.110 whittaker:0.102 insulin:0.093 fischell:0.086 \n",
      "==========================================================================================\n",
      "Cluster 96  (92 docs)\n",
      "film:0.248 festival:0.071 films:0.059 documentary:0.049 for:0.044 \n",
      "==========================================================================================\n",
      "Cluster 97  (11 docs)\n",
      "appeared:0.103 he:0.093 as:0.064 sal:0.056 film:0.055 \n",
      "==========================================================================================\n",
      "Cluster 98  (225 docs)\n",
      "she:0.199 her:0.071 was:0.049 for:0.042 as:0.038 \n",
      "==========================================================================================\n",
      "Cluster 99  (20 docs)\n",
      "haiti:0.072 haitian:0.065 he:0.054 news:0.053 she:0.052 \n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "visualize_document_clusters(wiki, tf_idf, all_centroids[k], all_cluster_assignment[k], k,\n",
    "                            words, display_docs=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhM16_W4o2hK"
   },
   "source": [
    "**A high value of K encourages pure clusters, but we cannot keep increasing K. For large enough K, related documents end up going to different clusters.**\n",
    "\n",
    "That said, the result for K=100 is not entirely bad. After all, it gives us separate clusters for such categories as Scotland, Brazil, LGBT, computer science and the Mormon Church. If we set K somewhere between 25 and 100, we should be able to avoid breaking up clusters while discovering new ones.\n",
    "\n",
    "Also, we should ask ourselves how much **granularity** we want in our clustering. If we wanted a rough sketch of Wikipedia, we don't want too detailed clusters. On the other hand, having many clusters can be valuable when we are zooming into a certain part of Wikipedia.\n",
    "\n",
    "**There is no golden rule for choosing K. It all depends on the particular application and domain we are in.**\n",
    "\n",
    "Another heuristic people use that does not rely on so much visualization, which can be hard in many applications (including here!) is as follows.  Track heterogeneity versus K and look for the \"elbow\" of the curve where the heterogeneity decrease rapidly before this value of K, but then only gradually for larger values of K.  This naturally trades off between trying to minimize heterogeneity, but reduce model complexity.  In the heterogeneity versus K plot made above, we did not yet really see a flattening out of the heterogeneity, which might indicate that indeed K=100 is \"reasonable\" and we only see real overfitting for larger values of K (which are even harder to visualize using the methods we attempted above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9xN6TPZo2hK"
   },
   "source": [
    "## üîç **Question 8** Small clusters\n",
    "\n",
    "Another sign of too large K is having lots of small clusters. Look at the distribution of cluster sizes (by number of member data points). When doing k-means with k=100, how many of the clusters have fewer than 44 articles (i.e. 0.004% of the dataset)?\n",
    "\n",
    "Save your result in a variable called `num_small_clustesrs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "1dZ1kYzTo2hK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "### edTest(test_q8_small_clusters) ###\n",
    "\n",
    "# TODO count clusters with fewer than 44 articles\n",
    "centroids, cluster_assignment = kmeans(tf_idf, 100, smart_initialize(tf_idf, 100), max_iter=400, record_heterogeneity=None, verbose=False)\n",
    "num_small_clusters = np.sum(np.bincount(cluster_assignment) < 44)\n",
    "print(num_small_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgtjdPZKo2hK"
   },
   "source": [
    "Keep in mind though that tiny clusters aren't necessarily bad. A tiny cluster of documents that really look like each others is definitely preferable to a medium-sized cluster of documents with mixed content. However, having too few articles in a cluster may lead us to question if that cluster is really worth separating from the others."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KEeFd0PBo2g0",
    "lyHkFDy0o2g0",
    "9hFrWT1Yo2g1",
    "e0UQT5SKo2g2",
    "c990JKsao2g3",
    "TWkIrMQvo2g3",
    "RTD6v4Sao2g6",
    "RtHVvmZ0o2g7",
    "pEkoWc6po2g8",
    "7-k9mXeGo2g9",
    "ySIw0ENho2g-",
    "ZRMReDFDo2g-",
    "8LJPdfM5o2g_",
    "rVskmXloo2hA",
    "n1dX6FT1o2hA",
    "BeTT70ORo2hA",
    "d9xN6TPZo2hK"
   ],
   "name": "HW6_k_means_with_text_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
